{"bibcode": "2020A&A...641A...6P", "title": "Planck 2018 results. VI. Cosmological parameters", "abstract": "We present cosmological parameter results from the final full-mission Planck measurements of the cosmic microwave background (CMB) anisotropies, combining information from the temperature and polarization maps and the lensing reconstruction. Compared to the 2015 results, improved measurements of large-scale polarization allow the reionization optical depth to be measured with higher precision, leading to significant gains in the precision of other correlated parameters. Improved modelling of the small-scale polarization leads to more robust constraints on many parameters, with residual modelling uncertainties estimated to affect them only at the 0.5σ level. We find good consistency with the standard spatially-flat 6-parameter ΛCDM cosmology having a power-law spectrum of adiabatic scalar perturbations (denoted \"base ΛCDM\" in this paper), from polarization, temperature, and lensing, separately and in combination. A combined analysis gives dark matter density Ω<SUB>c</SUB>h<SUP>2</SUP> = 0.120 ± 0.001, baryon density Ω<SUB>b</SUB>h<SUP>2</SUP> = 0.0224 ± 0.0001, scalar spectral index n<SUB>s</SUB> = 0.965 ± 0.004, and optical depth τ = 0.054 ± 0.007 (in this abstract we quote 68% confidence regions on measured parameters and 95% on upper limits). The angular acoustic scale is measured to 0.03% precision, with 100θ<SUB>*</SUB> = 1.0411 ± 0.0003. These results are only weakly dependent on the cosmological model and remain stable, with somewhat increased errors, in many commonly considered extensions. Assuming the base-ΛCDM cosmology, the inferred (model-dependent) late-Universe parameters are: Hubble constant H<SUB>0</SUB> = (67.4 ± 0.5) km s<SUP>-1</SUP> Mpc<SUP>-1</SUP>; matter density parameter Ω<SUB>m</SUB> = 0.315 ± 0.007; and matter fluctuation amplitude σ<SUB>8</SUB> = 0.811 ± 0.006. We find no compelling evidence for extensions to the base-ΛCDM model. Combining with baryon acoustic oscillation (BAO) measurements (and considering single-parameter extensions) we constrain the effective extra relativistic degrees of freedom to be N<SUB>eff</SUB> = 2.99 ± 0.17, in agreement with the Standard Model prediction N<SUB>eff</SUB> = 3.046, and find that the neutrino mass is tightly constrained to ∑m<SUB>ν</SUB> &lt; 0.12 eV. The CMB spectra continue to prefer higher lensing amplitudes than predicted in base ΛCDM at over 2σ, which pulls some parameters that affect the lensing amplitude away from the ΛCDM model; however, this is not supported by the lensing reconstruction or (in models that also change the background geometry) BAO data. The joint constraint with BAO measurements on spatial curvature is consistent with a flat universe, Ω<SUB>K</SUB> = 0.001 ± 0.002. Also combining with Type Ia supernovae (SNe), the dark-energy equation of state parameter is measured to be w<SUB>0</SUB> = -1.03 ± 0.03, consistent with a cosmological constant. We find no evidence for deviations from a purely power-law primordial spectrum, and combining with data from BAO, BICEP2, and Keck Array data, we place a limit on the tensor-to-scalar ratio r<SUB>0.002</SUB> &lt; 0.06. Standard big-bang nucleosynthesis predictions for the helium and deuterium abundances for the base-ΛCDM cosmology are in excellent agreement with observations. The Planck base-ΛCDM results are in good agreement with BAO, SNe, and some galaxy lensing observations, but in slight tension with the Dark Energy Survey's combined-probe results including galaxy clustering (which prefers lower fluctuation amplitudes or matter density parameters), and in significant, 3.6σ, tension with local measurements of the Hubble constant (which prefer a higher value). Simple model extensions that can partially resolve these tensions are not favoured by the Planck data.", "database": ["astronomy"], "keywords": ["cosmic background radiation", "cosmological parameters", "Astrophysics - Cosmology and Nongalactic Astrophysics"], "year": "2020", "doctype": "article", "citation_count": 17888, "domain_category": "astronomy"}
{"bibcode": "1998AJ....116.1009R", "title": "Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant", "abstract": "We present spectral and photometric observations of 10 Type Ia supernovae (SNe Ia) in the redshift range 0.16 &lt;= z &lt;= 0.62. The luminosity distances of these objects are determined by methods that employ relations between SN Ia luminosity and light curve shape. Combined with previous data from our High-z Supernova Search Team and recent results by Riess et al., this expanded set of 16 high-redshift supernovae and a set of 34 nearby supernovae are used to place constraints on the following cosmological parameters: the Hubble constant (H_0), the mass density (Omega_M), the cosmological constant (i.e., the vacuum energy density, Omega_Lambda), the deceleration parameter (q_0), and the dynamical age of the universe (t_0). The distances of the high-redshift SNe Ia are, on average, 10%-15% farther than expected in a low mass density (Omega_M = 0.2) universe without a cosmological constant. Different light curve fitting methods, SN Ia subsamples, and prior constraints unanimously favor eternally expanding models with positive cosmological constant (i.e., Omega_Lambda &gt; 0) and a current acceleration of the expansion (i.e., q_0 &lt; 0). With no prior constraint on mass density other than Omega_M &gt;= 0, the spectroscopically confirmed SNe Ia are statistically consistent with q_0 &lt; 0 at the 2.8 sigma and 3.9 sigma confidence levels, and with Omega_Lambda &gt; 0 at the 3.0 sigma and 4.0 sigma confidence levels, for two different fitting methods, respectively. Fixing a ``minimal'' mass density, Omega_M = 0.2, results in the weakest detection, Omega_Lambda &gt; 0 at the 3.0 sigma confidence level from one of the two methods. For a flat universe prior (Omega_M + Omega_Lambda = 1), the spectroscopically confirmed SNe Ia require Omega_Lambda &gt; 0 at 7 sigma and 9 sigma formal statistical significance for the two different fitting methods. A universe closed by ordinary matter (i.e., Omega_M = 1) is formally ruled out at the 7 sigma to 8 sigma confidence level for the two different fitting methods. We estimate the dynamical age of the universe to be 14.2 +/- 1.7 Gyr including systematic uncertainties in the current Cepheid distance scale. We estimate the likely effect of several sources of systematic error, including progenitor and metallicity evolution, extinction, sample selection bias, local perturbations in the expansion rate, gravitational lensing, and sample contamination. Presently, none of these effects appear to reconcile the data with Omega_Lambda = 0 and q_0 &gt;= 0.", "database": ["astronomy"], "keywords": ["COSMOLOGY: OBSERVATIONS", "STARS: SUPERNOVAE: GENERAL", "Astrophysics"], "year": "1998", "doctype": "article", "citation_count": 17679, "domain_category": "astronomy"}
{"bibcode": "1999ApJ...517..565P", "title": "Measurements of Ω and Λ from 42 High-Redshift Supernovae", "abstract": "We report measurements of the mass density, Ω<SUB>M</SUB>, and cosmological-constant energy density, Ω<SUB>Λ</SUB>, of the universe based on the analysis of 42 type Ia supernovae discovered by the Supernova Cosmology Project. The magnitude-redshift data for these supernovae, at redshifts between 0.18 and 0.83, are fitted jointly with a set of supernovae from the Calán/Tololo Supernova Survey, at redshifts below 0.1, to yield values for the cosmological parameters. All supernova peak magnitudes are standardized using a SN Ia light-curve width-luminosity relation. The measurement yields a joint probability distribution of the cosmological parameters that is approximated by the relation 0.8Ω<SUB>M</SUB>-0.6Ω<SUB>Λ</SUB>~-0.2+/-0.1 in the region of interest (Ω<SUB>M</SUB>&lt;~1.5). For a flat (Ω<SUB>M</SUB>+Ω<SUB>Λ</SUB>=1) cosmology we find Ω<SUP>flat</SUP><SUB>M</SUB>=0.28<SUP>+0.09</SUP><SUB>-0.08</SUB> (1 σ statistical) <SUP>+0.05</SUP><SUB>-0.04</SUB> (identified systematics). The data are strongly inconsistent with a Λ=0 flat cosmology, the simplest inflationary universe model. An open, Λ=0 cosmology also does not fit the data well: the data indicate that the cosmological constant is nonzero and positive, with a confidence of P(Λ&gt;0)=99%, including the identified systematic uncertainties. The best-fit age of the universe relative to the Hubble time is t<SUP>flat</SUP><SUB>0</SUB>=14.9<SUP>+1.4</SUP><SUB>-1.1</SUB>(0.63/h) Gyr for a flat cosmology. The size of our sample allows us to perform a variety of statistical tests to check for possible systematic errors and biases. We find no significant differences in either the host reddening distribution or Malmquist bias between the low-redshift Calán/Tololo sample and our high-redshift sample. Excluding those few supernovae that are outliers in color excess or fit residual does not significantly change the results. The conclusions are also robust whether or not a width-luminosity relation is used to standardize the supernova peak magnitudes. We discuss and constrain, where possible, hypothetical alternatives to a cosmological constant.", "database": ["astronomy", "physics"], "keywords": ["COSMOLOGY: OBSERVATIONS", "COSMOLOGY: DISTANCE SCALE", "STARS: SUPERNOVAE: GENERAL", "Cosmology: Observations", "Cosmology: Distance Scale", "Stars: Supernovae: General", "Astrophysics", "High Energy Physics - Experiment", "High Energy Physics - Phenomenology"], "year": "1999", "doctype": "article", "citation_count": 16899, "domain_category": "astronomy"}
{"bibcode": "2020NatMe..17..261V", "title": "SciPy 1.0: fundamental algorithms for scientific computing in Python", "abstract": "SciPy is an open source scientific computing library for the Python programming language. SciPy 1.0 was released in late 2017, about 16 years after the original version 0.1 release. SciPy has become a de facto standard for leveraging scientific algorithms in the Python programming language, with more than 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories, and millions of downloads per year. This includes usage of SciPy in almost half of all machine learning projects on GitHub, and usage by high profile projects including LIGO gravitational wave analysis and creation of the first-ever image of a black hole (M87). The library includes functionality spanning clustering, Fourier transforms, integration, interpolation, file I/O, linear algebra, image processing, orthogonal distance regression, minimization algorithms, signal processing, sparse matrix handling, computational geometry, and statistics. In this work, we provide an overview of the capabilities and development practices of the SciPy library and highlight some recent technical developments.", "database": ["astronomy", "physics", "general"], "keywords": ["Computer Science - Mathematical Software", "Computer Science - Data Structures and Algorithms", "Computer Science - Software Engineering", "Physics - Computational Physics"], "year": "2020", "doctype": "article", "citation_count": 16654, "domain_category": "astronomy"}
{"bibcode": "1998ApJ...500..525S", "title": "Maps of Dust Infrared Emission for Use in Estimation of Reddening and Cosmic Microwave Background Radiation Foregrounds", "abstract": "We present a full-sky 100 μm map that is a reprocessed composite of the COBE/DIRBE and IRAS/ISSA maps, with the zodiacal foreground and confirmed point sources removed. Before using the ISSA maps, we remove the remaining artifacts from the IRAS scan pattern. Using the DIRBE 100 and 240 μm data, we have constructed a map of the dust temperature so that the 100 μm map may be converted to a map proportional to dust column density. The dust temperature varies from 17 to 21 K, which is modest but does modify the estimate of the dust column by a factor of 5. The result of these manipulations is a map with DIRBE quality calibration and IRAS resolution. A wealth of filamentary detail is apparent on many different scales at all Galactic latitudes. In high-latitude regions, the dust map correlates well with maps of H I emission, but deviations are coherent in the sky and are especially conspicuous in regions of saturation of H I emission toward denser clouds and of formation of H<SUB>2</SUB> in molecular clouds. In contrast, high-velocity H I clouds are deficient in dust emission, as expected. <P />To generate the full-sky dust maps, we must first remove zodiacal light contamination, as well as a possible cosmic infrared background (CIB). This is done via a regression analysis of the 100 μm DIRBE map against the Leiden-Dwingeloo map of H I emission, with corrections for the zodiacal light via a suitable expansion of the DIRBE 25 μm flux. This procedure removes virtually all traces of the zodiacal foreground. For the 100 μm map no significant CIB is detected. At longer wavelengths, where the zodiacal contamination is weaker, we detect the CIB at surprisingly high flux levels of 32 +/- 13 nW m<SUP>-2</SUP> sr<SUP>-1</SUP> at 140 μm and of 17 +/- 4 nW m<SUP>-2</SUP> sr<SUP>-1</SUP> at 240 μm (95% confidence). This integrated flux ~2 times that extrapolated from optical galaxies in the Hubble Deep Field. <P />The primary use of these maps is likely to be as a new estimator of Galactic extinction. To calibrate our maps, we assume a standard reddening law and use the colors of elliptical galaxies to measure the reddening per unit flux density of 100 μm emission. We find consistent calibration using the B-R color distribution of a sample of the 106 brightest cluster ellipticals, as well as a sample of 384 ellipticals with B-V and Mg line strength measurements. For the latter sample, we use the correlation of intrinsic B-V versus Mg<SUB>2</SUB> index to tighten the power of the test greatly. We demonstrate that the new maps are twice as accurate as the older Burstein-Heiles reddening estimates in regions of low and moderate reddening. The maps are expected to be significantly more accurate in regions of high reddening. These dust maps will also be useful for estimating millimeter emission that contaminates cosmic microwave background radiation experiments and for estimating soft X-ray absorption. We describe how to access our maps readily for general use.", "database": ["astronomy"], "keywords": ["COSMOLOGY: DIFFUSE RADIATION", "COSMOLOGY: COSMIC MICROWAVE BACKGROUND", "ISM: DUST", "EXTINCTION", "INTERPLANETARY MEDIUM", "INFRARED: ISM: CONTINUUM", "Cosmology: Cosmic Microwave Background", "Cosmology: Diffuse Radiation", "ISM: Dust", "Extinction", "Infrared: ISM: Continuum", "Interplanetary Medium", "Astrophysics"], "year": "1998", "doctype": "article", "citation_count": 13918, "domain_category": "astronomy"}
{"bibcode": "2016A&A...594A..13P", "title": "Planck 2015 results. XIII. Cosmological parameters", "abstract": "This paper presents cosmological results based on full-mission Planck observations of temperature and polarization anisotropies of the cosmic microwave background (CMB) radiation. Our results are in very good agreement with the 2013 analysis of the Planck nominal-mission temperature data, but with increased precision. The temperature and polarization power spectra are consistent with the standard spatially-flat 6-parameter ΛCDM cosmology with a power-law spectrum of adiabatic scalar perturbations (denoted \"base ΛCDM\" in this paper). From the Planck temperature data combined with Planck lensing, for this cosmology we find a Hubble constant, H<SUB>0</SUB> = (67.8 ± 0.9) km s<SUP>-1</SUP>Mpc<SUP>-1</SUP>, a matter density parameter Ω<SUB>m</SUB> = 0.308 ± 0.012, and a tilted scalar spectral index with n<SUB>s</SUB> = 0.968 ± 0.006, consistent with the 2013 analysis. Note that in this abstract we quote 68% confidence limits on measured parameters and 95% upper limits on other parameters. We present the first results of polarization measurements with the Low Frequency Instrument at large angular scales. Combined with the Planck temperature and lensing data, these measurements give a reionization optical depth of τ = 0.066 ± 0.016, corresponding to a reionization redshift of z_re=8.8<SUP>+1.7</SUP><SUB>-1.4</SUB>. These results are consistent with those from WMAP polarization measurements cleaned for dust emission using 353-GHz polarization maps from the High Frequency Instrument. We find no evidence for any departure from base ΛCDM in the neutrino sector of the theory; for example, combining Planck observations with other astrophysical data we find N<SUB>eff</SUB> = 3.15 ± 0.23 for the effective number of relativistic degrees of freedom, consistent with the value N<SUB>eff</SUB> = 3.046 of the Standard Model of particle physics. The sum of neutrino masses is constrained to ∑ m<SUB>ν</SUB> &lt; 0.23 eV. The spatial curvature of our Universe is found to be very close to zero, with | Ω<SUB>K</SUB> | &lt; 0.005. Adding a tensor component as a single-parameter extension to base ΛCDM we find an upper limit on the tensor-to-scalar ratio of r<SUB>0.002</SUB>&lt; 0.11, consistent with the Planck 2013 results and consistent with the B-mode polarization constraints from a joint analysis of BICEP2, Keck Array, and Planck (BKP) data. Adding the BKP B-mode data to our analysis leads to a tighter constraint of r<SUB>0.002</SUB> &lt; 0.09 and disfavours inflationarymodels with a V(φ) ∝ φ<SUP>2</SUP> potential. The addition of Planck polarization data leads to strong constraints on deviations from a purely adiabatic spectrum of fluctuations. We find no evidence for any contribution from isocurvature perturbations or from cosmic defects. Combining Planck data with other astrophysical data, including Type Ia supernovae, the equation of state of dark energy is constrained to w = -1.006 ± 0.045, consistent with the expected value for a cosmological constant. The standard big bang nucleosynthesis predictions for the helium and deuterium abundances for the best-fit Planck base ΛCDM cosmology are in excellent agreement with observations. We also constraints on annihilating dark matter and on possible deviations from the standard recombination history. In neither case do we find no evidence for new physics. The Planck results for base ΛCDM are in good agreement with baryon acoustic oscillation data and with the JLA sample of Type Ia supernovae. However, as in the 2013 analysis, the amplitude of the fluctuation spectrum is found to be higher than inferred from some analyses of rich cluster counts and weak gravitational lensing. We show that these tensions cannot easily be resolved with simple modifications of the base ΛCDM cosmology. Apart from these tensions, the base ΛCDM cosmology provides an excellent description of the Planck CMB observations and many other astrophysical data sets. <P /></SUP>", "database": ["astronomy"], "keywords": ["cosmology: observations", "cosmology: theory", "cosmic background radiation", "cosmological parameters", "Astrophysics - Cosmology and Nongalactic Astrophysics"], "year": "2016", "doctype": "article", "citation_count": 13296, "domain_category": "astronomy"}
{"bibcode": "1973A&A....24..337S", "title": "Black holes in binary systems. Observational appearance.", "abstract": "The outward transfer of the angular momentum of the accreting matter leads to the formation of a disk around the black hole. The structure and radiation spectrum of the disk depend, mainly on the rate of matter inflow A into the disk at its external boundary The dependence on the efficiency of mechanisms of angular momentum transport (connected with the magnetic field and turbulence) is weaker. If A = 1O<SUP>-3</SUP>-1O<SUP>-8</SUP> M⊙ the disk around the black hole is a year powerful source of X-ray radiation with hv 1- 10 keV and luminosity L 1O - 10<SUP>38</SUP> erg/s. If the flux of the accreting matter decreases, the effective temperature of the radiation and the luminosity will drop. On the other hand, when M &gt; 1O- M⊙ the optical luminosity year of the disk exceeds the solar value. The main contribution to the optical luminosity of the black hole arises from reradiation of that part of the X-ray and ultra-violet energy which is initially produced in the central high temperature regions of the disk and which is then absorbed by the low temperature outer regions. saturated by broad recombination and resonance emission lines. Variability, connected with the character of the motion of the black hole, with gas flows in a binary system and with eclipses, is possible. Under certain conditions, the hard radiation can evaporate the gas. This can counteract the matter inflow into the disk and lead to autoregulation of the accretion. If M 3×10<SUP>-8</SUP> M⊙ the luminosity of the disk around year the black hole is stabilized at the critical level of L 1038 M erg A small fraction of the accreting M⊙ s matter falls under the gravitational radius whereas the major part of it flows out with high velocity from the central regions of the disk. The outflowing matter is opaque to the disk radiation and completely transforms its spectrum.", "database": ["astronomy"], "keywords": [], "year": "1973", "doctype": "article", "citation_count": 13267, "domain_category": "astronomy"}
{"bibcode": "2016PhRvL.116f1102A", "title": "Observation of Gravitational Waves from a Binary Black Hole Merger", "abstract": "On September 14, 2015 at 09:50:45 UTC the two detectors of the Laser Interferometer Gravitational-Wave Observatory simultaneously observed a transient gravitational-wave signal. The signal sweeps upwards in frequency from 35 to 250 Hz with a peak gravitational-wave strain of 1.0 ×10<SUP>-21</SUP>. It matches the waveform predicted by general relativity for the inspiral and merger of a pair of black holes and the ringdown of the resulting single black hole. The signal was observed with a matched-filter signal-to-noise ratio of 24 and a false alarm rate estimated to be less than 1 event per 203 000 years, equivalent to a significance greater than 5.1 σ . The source lies at a luminosity distance of 41 0<SUB>-180</SUB><SUP>+160</SUP> Mpc corresponding to a redshift z =0.0 9<SUB>-0.04</SUB><SUP>+0.03</SUP> . In the source frame, the initial black hole masses are 3 6<SUB>-4</SUB><SUP>+5</SUP>M<SUB>⊙</SUB> and 2 9<SUB>-4</SUB><SUP>+4</SUP>M<SUB>⊙</SUB> , and the final black hole mass is 6 2<SUB>-4</SUB><SUP>+4</SUP>M<SUB>⊙</SUB> , with 3. 0<SUB>-0.5</SUB><SUP>+0.5</SUP>M<SUB>⊙</SUB> c<SUP>2</SUP> radiated in gravitational waves. All uncertainties define 90% credible intervals. These observations demonstrate the existence of binary stellar-mass black hole systems. This is the first direct detection of gravitational waves and the first observation of a binary black hole merger.", "database": ["astronomy", "physics"], "keywords": ["General Relativity and Quantum Cosmology", "Astrophysics - High Energy Astrophysical Phenomena"], "year": "2016", "doctype": "article", "citation_count": 12879, "domain_category": "astronomy"}
{"bibcode": "1975CMaPh..43..199H", "title": "Particle creation by black holes", "abstract": "In the classical theory black holes can only absorb and not emit particles. However it is shown that quantum mechanical effects cause black holes to create and emit particles as if they were hot bodies with temperature{hkappa }/{2π k} ≈ 10^{ - 6} left( {{M_ odot }/M} right){}^ circ K where κ is the surface gravity of the black hole. This thermal emission leads to a slow decrease in the mass of the black hole and to its eventual disappearance: any primordial black hole of mass less than about 10<SUP>15</SUP> g would have evaporated by now. Although these quantum effects violate the classical law that the area of the event horizon of a black hole cannot decrease, there remains a Generalized Second Law: S+1/4 A never decreases where S is the entropy of matter outside black holes and A is the sum of the surface areas of the event horizons. This shows that gravitational collapse converts the baryons and leptons in the collapsing body into entropy. It is tempting to speculate that this might be the reason why the Universe contains so much entropy per baryon.", "database": ["astronomy", "physics"], "keywords": [], "year": "1975", "doctype": "article", "citation_count": 10749, "domain_category": "astronomy"}
{"bibcode": "2003ApJS..148..175S", "title": "First-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Determination of Cosmological Parameters", "abstract": "WMAP precision data enable accurate testing of cosmological models. We find that the emerging standard model of cosmology, a flat Λ-dominated universe seeded by a nearly scale-invariant adiabatic Gaussian fluctuations, fits the WMAP data. For the WMAP data only, the best-fit parameters are h=0.72+/-0.05, Ω<SUB>b</SUB>h<SUP>2</SUP>=0.024+/-0.001, Ω<SUB>m</SUB>h<SUP>2</SUP>=0.14+/-0.02, τ=0.166<SUP>+0.076</SUP><SUB>-0.071</SUB>, n<SUB>s</SUB>=0.99+/-0.04, and σ<SUB>8</SUB>=0.9+/-0.1. With parameters fixed only by WMAP data, we can fit finer scale cosmic microwave background (CMB) measurements and measurements of large-scale structure (galaxy surveys and the Lyα forest). This simple model is also consistent with a host of other astronomical measurements: its inferred age of the universe is consistent with stellar ages, the baryon/photon ratio is consistent with measurements of the [D/H] ratio, and the inferred Hubble constant is consistent with local observations of the expansion rate. We then fit the model parameters to a combination of WMAP data with other finer scale CMB experiments (ACBAR and CBI), 2dFGRS measurements, and Lyα forest data to find the model's best-fit cosmological parameters: h=0.71<SUP>+0.04</SUP><SUB>-0.03</SUB>, Ω<SUB>b</SUB>h<SUP>2</SUP>=0.0224+/-0.0009, Ω<SUB>m</SUB>h<SUP>2</SUP>=0.135<SUP>+0.008</SUP><SUB>-0.009</SUB>, τ=0.17+/-0.06, n<SUB>s</SUB>(0.05 Mpc<SUP>-1</SUP>)=0.93+/-0.03, and σ<SUB>8</SUB>=0.84+/-0.04. WMAP's best determination of τ=0.17+/-0.04 arises directly from the temperature-polarization (TE) data and not from this model fit, but they are consistent. These parameters imply that the age of the universe is 13.7+/-0.2 Gyr. With the Lyα forest data, the model favors but does not require a slowly varying spectral index. The significance of this running index is sensitive to the uncertainties in the Lyα forest. <P />By combining WMAP data with other astronomical data, we constrain the geometry of the universe, Ω<SUB>tot</SUB>=1.02+/-0.02, and the equation of state of the dark energy, w&lt;-0.78 (95% confidence limit assuming w&gt;=-1). The combination of WMAP and 2dFGRS data constrains the energy density in stable neutrinos: Ω<SUB>ν</SUB>h<SUP>2</SUP>&lt;0.0072 (95% confidence limit). For three degenerate neutrino species, this limit implies that their mass is less than 0.23 eV (95% confidence limit). The WMAP detection of early reionization rules out warm dark matter. <P />WMAP is the result of a partnership between Princeton University and the NASA Goddard Space Flight Center. Scientific guidance is provided by the WMAP Science Team.", "database": ["astronomy"], "keywords": ["Cosmology: Cosmic Microwave Background", "Cosmology: Cosmological Parameters- Cosmology: Observations", "Cosmology: Early Universe", "Astrophysics"], "year": "2003", "doctype": "article", "citation_count": 10645, "domain_category": "astronomy"}
{"bibcode": "1996A&AS..117..393B", "title": "SExtractor: Software for source extraction.", "abstract": "We present the automated techniques we have developed for new software that optimally detects, de-blends, measures and classifies sources from astronomical images: SExtractor (Source Extractor). We show that a very reliable star/galaxy separation can be achieved on most images using a neural network trained with simulated images. Salient features of SExtractor include its ability to work on very large images, with minimal human intervention, and to deal with a wide variety of object shapes and magnitudes. It is therefore particularly suited to the analysis of large extragalactic surveys.", "database": ["astronomy"], "keywords": ["METHODS: DATA ANALYSIS", "TECHNIQUES: IMAGE PROCESSING", "GALAXIES: PHOTOMETRY"], "year": "1996", "doctype": "article", "citation_count": 10143, "domain_category": "astronomy"}
{"bibcode": "1997ApJ...490..493N", "title": "A Universal Density Profile from Hierarchical Clustering", "abstract": "We use high-resolution N-body simulations to study the equilibrium density profiles of dark matter halos in hierarchically clustering universes. We find that all such profiles have the same shape, independent of the halo mass, the initial density fluctuation spectrum, and the values of the cosmological parameters. Spherically averaged equilibrium profiles are well fitted over two decades in radius by a simple formula originally proposed to describe the structure of galaxy clusters in a cold dark matter universe. In any particular cosmology, the two scale parameters of the fit, the halo mass and its characteristic density, are strongly correlated. Low-mass halos are significantly denser than more massive systems, a correlation that reflects the higher collapse redshift of small halos. The characteristic density of an equilibrium halo is proportional to the density of the universe at the time it was assembled. A suitable definition of this assembly time allows the same proportionality constant to be used for all the cosmologies that we have tested. We compare our results with previous work on halo density profiles and show that there is good agreement. We also provide a step-by-step analytic procedure, based on the Press-Schechter formalism, that allows accurate equilibrium profiles to be calculated as a function of mass in any hierarchical model.", "database": ["astronomy"], "keywords": ["Cosmology: Theory", "Cosmology: Dark Matter", "Galaxies: Halos", "Methods: Numerical", "Astrophysics"], "year": "1997", "doctype": "article", "citation_count": 9847, "domain_category": "astronomy"}
{"bibcode": "2000AJ....120.1579Y", "title": "The Sloan Digital Sky Survey: Technical Summary", "abstract": "The Sloan Digital Sky Survey (SDSS) will provide the data to support detailed investigations of the distribution of luminous and nonluminous matter in the universe: a photometrically and astrometrically calibrated digital imaging survey of π sr above about Galactic latitude 30° in five broad optical bands to a depth of g'~23 mag, and a spectroscopic survey of the approximately 10<SUP>6</SUP> brightest galaxies and 10<SUP>5</SUP> brightest quasars found in the photometric object catalog produced by the imaging survey. This paper summarizes the observational parameters and data products of the SDSS and serves as an introduction to extensive technical on-line documentation.", "database": ["astronomy"], "keywords": ["Cosmology: Observations", "Instrumentation: Miscellaneous", "Astrophysics"], "year": "2000", "doctype": "article", "citation_count": 9713, "domain_category": "astronomy"}
{"bibcode": "2003MNRAS.344.1000B", "title": "Stellar population synthesis at the resolution of 2003", "abstract": "We present a new model for computing the spectral evolution of stellar populations at ages between 1 × 10<SUP>5</SUP> and 2 × 10<SUP>10</SUP> yr at a resolution of 3 Å across the whole wavelength range from 3200 to 9500 Å for a wide range of metallicities. These predictions are based on a newly available library of observed stellar spectra. We also compute the spectral evolution across a larger wavelength range, from 91 Å to 160 μm, at lower resolution. The model incorporates recent progress in stellar evolution theory and an observationally motivated prescription for thermally pulsing stars on the asymptotic giant branch. The latter is supported by observations of surface brightness fluctuations in nearby stellar populations. We show that this model reproduces well the observed optical and near-infrared colour-magnitude diagrams of Galactic star clusters of various ages and metallicities. Stochastic fluctuations in the numbers of stars in different evolutionary phases can account for the full range of observed integrated colours of star clusters in the Magellanic Clouds. The model reproduces in detail typical galaxy spectra from the Early Data Release (EDR) of the Sloan Digital Sky Survey (SDSS). We exemplify how this type of spectral fit can constrain physical parameters such as the star formation history, metallicity and dust content of galaxies. Our model is the first to enable accurate studies of absorption-line strengths in galaxies containing stars over the full range of ages. Using the highest-quality spectra of the SDSS EDR, we show that this model can reproduce simultaneously the observed strengths of those Lick indices that do not depend strongly on element abundance ratios. The interpretation of such indices with our model should be particularly useful for constraining the star formation histories and metallicities of galaxies.", "database": ["astronomy"], "keywords": ["stars: evolution", "galaxies: evolution", "galaxies: formation", "galaxies: stellar content", "Astrophysics"], "year": "2003", "doctype": "article", "citation_count": 9674, "domain_category": "astronomy"}
{"bibcode": "2017PhRvL.119p1101A", "title": "GW170817: Observation of Gravitational Waves from a Binary Neutron Star Inspiral", "abstract": "On August 17, 2017 at 12∶41:04 UTC the Advanced LIGO and Advanced Virgo gravitational-wave detectors made their first observation of a binary neutron star inspiral. The signal, GW170817, was detected with a combined signal-to-noise ratio of 32.4 and a false-alarm-rate estimate of less than one per <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mrow><mml:mn>8.0</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>years</mml:mi></mml:mrow></mml:math></inline-formula>. We infer the component masses of the binary to be between 0.86 and <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mn>2.26</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">⊙</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, in agreement with masses of known neutron stars. Restricting the component spins to the range inferred in binary neutron stars, we find the component masses to be in the range <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mn>1.17</mml:mn><mml:mi>–</mml:mi><mml:mn>1.60</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">⊙</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, with the total mass of the system <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mn>2.7</mml:mn><mml:msubsup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.01</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy=\"false\">⊙</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The source was localized within a sky region of <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mn>28</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mrow><mml:msup><mml:mrow><mml:mi>deg</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (90% probability) and had a luminosity distance of <inline-formula><mml:math display=\"inline\"><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:msubsup><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>14</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi>Mpc</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the closest and most precisely localized gravitational-wave signal yet. The association with the <inline-formula><mml:math display=\"inline\"><mml:mi>γ</mml:mi></mml:math></inline-formula>-ray burst GRB 170817A, detected by Fermi-GBM 1.7 s after the coalescence, corroborates the hypothesis of a neutron star merger and provides the first direct evidence of a link between these mergers and short <inline-formula><mml:math display=\"inline\"><mml:mi>γ</mml:mi></mml:math></inline-formula>-ray bursts. Subsequent identification of transient counterparts across the electromagnetic spectrum in the same location further supports the interpretation of this event as a neutron star merger. This unprecedented joint gravitational and electromagnetic observation provides insight into astrophysics, dense matter, gravitation, and cosmology.", "database": ["astronomy", "physics"], "keywords": ["Gravitation and Astrophysics", "General Relativity and Quantum Cosmology", "Astrophysics - High Energy Astrophysical Phenomena"], "year": "2017", "doctype": "article", "citation_count": 9224, "domain_category": "astronomy"}
{"bibcode": "2003PASP..115..763C", "title": "Galactic Stellar and Substellar Initial Mass Function", "abstract": "We review recent determinations of the present-day mass function (PDMF) and initial mass function (IMF) in various components of the Galaxy-disk, spheroid, young, and globular clusters-and in conditions characteristic of early star formation. As a general feature, the IMF is found to depend weakly on the environment and to be well described by a power-law form for m&gt;~1 M<SUB>solar</SUB> and a lognormal form below, except possibly for early star formation conditions. The disk IMF for single objects has a characteristic mass around m<SUB>c</SUB>~0.08 M<SUB>solar</SUB> and a variance in logarithmic mass σ~0.7, whereas the IMF for multiple systems has m<SUB>c</SUB>~0.2 M<SUB>solar</SUB> and σ~0.6. The extension of the single MF into the brown dwarf regime is in good agreement with present estimates of L- and T-dwarf densities and yields a disk brown dwarf number density comparable to the stellar one, n<SUB>BD</SUB>~n<SUB>*</SUB>~0.1 pc<SUP>-3</SUP>. The IMF of young clusters is found to be consistent with the disk field IMF, providing the same correction for unresolved binaries, confirming the fact that young star clusters and disk field stars represent the same stellar population. Dynamical effects, yielding depletion of the lowest mass objects, are found to become consequential for ages &gt;~130 Myr. The spheroid IMF relies on much less robust grounds. The large metallicity spread in the local subdwarf photometric sample, in particular, remains puzzling. Recent observations suggest that there is a continuous kinematic shear between the thick-disk population, present in local samples, and the genuine spheroid one. This enables us to derive only an upper limit for the spheroid mass density and IMF. Within all the uncertainties, the latter is found to be similar to the one derived for globular clusters and is well represented also by a lognormal form with a characteristic mass slightly larger than for the disk, m<SUB>c</SUB>~0.2-0.3 M<SUB>solar</SUB>, excluding a significant population of brown dwarfs in globular clusters and in the spheroid. The IMF characteristic of early star formation at large redshift remains undetermined, but different observational constraints suggest that it does not extend below ~1 M<SUB>solar</SUB>. These results suggest a characteristic mass for star formation that decreases with time, from conditions prevailing at large redshift to conditions characteristic of the spheroid (or thick disk) to present-day conditions. These conclusions, however, remain speculative, given the large uncertainties in the spheroid and early star IMF determinations. <P />These IMFs allow a reasonably robust determination of the Galactic present-day and initial stellar and brown dwarf contents. They also have important galactic implications beyond the Milky Way in yielding more accurate mass-to-light ratio determinations. The mass-to-light ratios obtained with the disk and the spheroid IMF yield values 1.8-1.4 times smaller than for a Salpeter IMF, respectively, in agreement with various recent dynamical determinations. This general IMF determination is examined in the context of star formation theory. None of the theories based on a Jeans-type mechanism, where fragmentation is due only to gravity, can fulfill all the observational constraints on star formation and predict a large number of substellar objects. On the other hand, recent numerical simulations of compressible turbulence, in particular in super-Alfvénic conditions, seem to reproduce both qualitatively and quantitatively the stellar and substellar IMF and thus provide an appealing theoretical foundation. In this picture, star formation is induced by the dissipation of large-scale turbulence to smaller scales through radiative MHD shocks, producing filamentary structures. These shocks produce local nonequilibrium structures with large density contrasts, which collapse eventually in gravitationally bound objects under the combined influence of turbulence and gravity. The concept of a single Jeans mass is replaced by a distribution of local Jeans masses, representative of the lognormal probability density function of the turbulent gas. Objects below the mean thermal Jeans mass still have a possibility to collapse, although with a decreasing probability. <P />The page charges for this Review were partially covered by a generous gift from a PASP supporter.", "database": ["astronomy"], "keywords": ["Galaxies: Luminosity Function", "Mass Function", "Invited Reviews", "Astrophysics"], "year": "2003", "doctype": "article", "citation_count": 8628, "domain_category": "astronomy"}
{"bibcode": "1955ApJ...121..161S", "title": "The Luminosity Function and Stellar Evolution.", "abstract": "The evolutionary significance of the observed luminosity function for main-sequence stars in the solar neighborhood is discussed. The hypothesis is made that stars move off the main sequence after burning about 10 per cent of their hydrogen mass and that stars have been created at a uniform rate in the solar neighborhood for the last five billion years. Using this hypothesis and the observed luminosity function, the rate of star creation as a function of stellar mass is calculated. The total number and mass of stars which have moved off the main sequence is found to be comparable with the total number of white dwarfs and with the total mass of all fainter main-sequence stars, respectively.", "database": ["astronomy"], "keywords": [], "year": "1955", "doctype": "article", "citation_count": 8578, "domain_category": "astronomy"}
{"bibcode": "2009ARA&A..47..481A", "title": "The Chemical Composition of the Sun", "abstract": "The solar chemical composition is an important ingredient in our understanding of the formation, structure, and evolution of both the Sun and our Solar System. Furthermore, it is an essential reference standard against which the elemental contents of other astronomical objects are compared. In this review, we evaluate the current understanding of the solar photospheric composition. In particular, we present a redetermination of the abundances of nearly all available elements, using a realistic new three-dimensional (3D), time-dependent hydrodynamical model of the solar atmosphere. We have carefully considered the atomic input data and selection of spectral lines, and accounted for departures from local thermodynamic equilibrium (LTE) whenever possible. The end result is a comprehensive and homogeneous compilation of the solar elemental abundances. Particularly noteworthy findings are significantly lower abundances of C, N, O, and Ne compared to the widely used values of a decade ago. The new solar chemical composition is supported by a high degree of internal consistency between available abundance indicators, and by agreement with values obtained in the Solar Neighborhood and from the most pristine meteorites. There is, however, a stark conflict with standard models of the solar interior according to helioseismology, a discrepancy that has yet to find a satisfactory resolution.", "database": ["astronomy"], "keywords": ["Astrophysics - Solar and Stellar Astrophysics", "Astrophysics - Earth and Planetary Astrophysics"], "year": "2009", "doctype": "article", "citation_count": 8379, "domain_category": "astronomy"}
{"bibcode": "2014A&A...571A..16P", "title": "Planck 2013 results. XVI. Cosmological parameters", "abstract": "This paper presents the first cosmological results based on Planck measurements of the cosmic microwave background (CMB) temperature and lensing-potential power spectra. We find that the Planck spectra at high multipoles (ℓ ≳ 40) are extremely well described by the standard spatially-flat six-parameter ΛCDM cosmology with a power-law spectrum of adiabatic scalar perturbations. Within the context of this cosmology, the Planck data determine the cosmological parameters to high precision: the angular size of the sound horizon at recombination, the physical densities of baryons and cold dark matter, and the scalar spectral index are estimated to be θ<SUB>∗</SUB> = (1.04147 ± 0.00062) × 10<SUP>-2</SUP>, Ω<SUB>b</SUB>h<SUP>2</SUP> = 0.02205 ± 0.00028, Ω<SUB>c</SUB>h<SUP>2</SUP> = 0.1199 ± 0.0027, and n<SUB>s</SUB> = 0.9603 ± 0.0073, respectively(note that in this abstract we quote 68% errors on measured parameters and 95% upper limits on other parameters). For this cosmology, we find a low value of the Hubble constant, H<SUB>0</SUB> = (67.3 ± 1.2) km s<SUP>-1</SUP> Mpc<SUP>-1</SUP>, and a high value of the matter density parameter, Ω<SUB>m</SUB> = 0.315 ± 0.017. These values are in tension with recent direct measurements of H<SUB>0</SUB> and the magnitude-redshift relation for Type Ia supernovae, but are in excellent agreement with geometrical constraints from baryon acoustic oscillation (BAO) surveys. Including curvature, we find that the Universe is consistent with spatial flatness to percent level precision using Planck CMB data alone. We use high-resolution CMB data together with Planck to provide greater control on extragalactic foreground components in an investigation of extensions to the six-parameter ΛCDM model. We present selected results from a large grid of cosmological models, using a range of additional astrophysical data sets in addition to Planck and high-resolution CMB data. None of these models are favoured over the standard six-parameter ΛCDM cosmology. The deviation of the scalar spectral index from unity isinsensitive to the addition of tensor modes and to changes in the matter content of the Universe. We find an upper limit of r<SUB>0.002</SUB>&lt; 0.11 on the tensor-to-scalar ratio. There is no evidence for additional neutrino-like relativistic particles beyond the three families of neutrinos in the standard model. Using BAO and CMB data, we find N<SUB>eff</SUB> = 3.30 ± 0.27 for the effective number of relativistic degrees of freedom, and an upper limit of 0.23 eV for the sum of neutrino masses. Our results are in excellent agreement with big bang nucleosynthesis and the standard value of N<SUB>eff</SUB> = 3.046. We find no evidence for dynamical dark energy; using BAO and CMB data, the dark energy equation of state parameter is constrained to be w = -1.13<SUB>-0.10</SUB><SUP>+0.13</SUP>. We also use the Planck data to set limits on a possible variation of the fine-structure constant, dark matter annihilation and primordial magnetic fields. Despite the success of the six-parameter ΛCDM model in describing the Planck data at high multipoles, we note that this cosmology does not provide a good fit to the temperature power spectrum at low multipoles. The unusual shape of the spectrum in the multipole range 20 ≲ ℓ ≲ 40 was seen previously in the WMAP data and is a real feature of the primordial CMB anisotropies. The poor fit to the spectrum at low multipoles is not of decisive significance, but is an \"anomaly\" in an otherwise self-consistent analysis of the Planck temperature data.", "database": ["astronomy"], "keywords": ["cosmic background radiation", "cosmological parameters", "early Universe", "inflation", "primordial nucleosynthesis", "Astrophysics - Cosmology and Nongalactic Astrophysics"], "year": "2014", "doctype": "article", "citation_count": 8373, "domain_category": "astronomy"}
{"bibcode": "2011ApJS..192...18K", "title": "Seven-year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Cosmological Interpretation", "abstract": "The combination of seven-year data from WMAP and improved astrophysical data rigorously tests the standard cosmological model and places new constraints on its basic parameters and extensions. By combining the WMAP data with the latest distance measurements from the baryon acoustic oscillations (BAO) in the distribution of galaxies and the Hubble constant (H <SUB>0</SUB>) measurement, we determine the parameters of the simplest six-parameter ΛCDM model. The power-law index of the primordial power spectrum is n<SUB>s</SUB> = 0.968 ± 0.012 (68% CL) for this data combination, a measurement that excludes the Harrison-Zel'dovich-Peebles spectrum by 99.5% CL. The other parameters, including those beyond the minimal set, are also consistent with, and improved from, the five-year results. We find no convincing deviations from the minimal model. The seven-year temperature power spectrum gives a better determination of the third acoustic peak, which results in a better determination of the redshift of the matter-radiation equality epoch. Notable examples of improved parameters are the total mass of neutrinos, ∑m <SUB>ν</SUB> &lt; 0.58 eV(95%CL), and the effective number of neutrino species, N <SUB>eff</SUB> = 4.34<SUP>+0.86</SUP> <SUB>-0.88</SUB> (68% CL), which benefit from better determinations of the third peak and H <SUB>0</SUB>. The limit on a constant dark energy equation of state parameter from WMAP+BAO+H <SUB>0</SUB>, without high-redshift Type Ia supernovae, is w = -1.10 ± 0.14 (68% CL). We detect the effect of primordial helium on the temperature power spectrum and provide a new test of big bang nucleosynthesis by measuring Y<SUB>p</SUB> = 0.326 ± 0.075 (68% CL). We detect, and show on the map for the first time, the tangential and radial polarization patterns around hot and cold spots of temperature fluctuations, an important test of physical processes at z = 1090 and the dominance of adiabatic scalar fluctuations. The seven-year polarization data have significantly improved: we now detect the temperature-E-mode polarization cross power spectrum at 21σ, compared with 13σ from the five-year data. With the seven-year temperature-B-mode cross power spectrum, the limit on a rotation of the polarization plane due to potential parity-violating effects has improved by 38% to Δ α =-1.1± 1.4° statistical ± 1.5 systematic (68% CL). We report significant detections of the Sunyaev-Zel'dovich (SZ) effect at the locations of known clusters of galaxies. The measured SZ signal agrees well with the expected signal from the X-ray data on a cluster-by-cluster basis. However, it is a factor of 0.5-0.7 times the predictions from \"universal profile\" of Arnaud et al., analytical models, and hydrodynamical simulations. We find, for the first time in the SZ effect, a significant difference between the cooling-flow and non-cooling-flow clusters (or relaxed and non-relaxed clusters), which can explain some of the discrepancy. This lower amplitude is consistent with the lower-than-theoretically expected SZ power spectrum recently measured by the South Pole Telescope Collaboration. <P />WMAP is the result of a partnership between Princeton University and NASA's Goddard Space Flight Center. Scientific guidance is provided by the WMAP Science Team.", "database": ["astronomy"], "keywords": ["cosmic background radiation", "cosmology: observations", "dark matter", "early universe", "space vehicles", "Astrophysics - Cosmology and Extragalactic Astrophysics"], "year": "2011", "doctype": "article", "citation_count": 8300, "domain_category": "astronomy"}
{"bibcode": "1985Natur.318..162K", "title": "C<SUB>60</SUB>: Buckminsterfullerene", "abstract": "During experiments aimed at understanding the mechanisms by which long-chain carbon molecules are formed in interstellar space and circumstellar shells<SUP>1</SUP>, graphite has been vaporized by laser irradiation, producing a remarkably stable cluster consisting of 60 carbon atoms. Concerning the question of what kind of 60-carbon atom structure might give rise to a superstable species, we suggest a truncated icosahedron, a polygon with 60 vertices and 32 faces, 12 of which are pentagonal and 20 hexagonal. This object is commonly encountered as the football shown in Fig. 1. The C<SUB>60</SUB> molecule which results when a carbon atom is placed at each vertex of this structure has all valences satisfied by two single bonds and one double bond, has many resonance structures, and appears to be aromatic.", "database": ["astronomy", "physics", "general"], "keywords": ["Carbon", "Cosmochemistry", "Graphite", "Laser Target Interactions", "Molecular Structure", "Argon Lasers", "Excimer Lasers", "Fluorides", "Interstellar Matter", "Mass Spectra", "Neodymium Lasers", "Stellar Envelopes", "Yag Lasers", "Atomic and Molecular Physics"], "year": "1985", "doctype": "article", "citation_count": 8216, "domain_category": "astronomy"}
{"bibcode": "1996ApJ...462..563N", "title": "The Structure of Cold Dark Matter Halos", "abstract": "We use N-body simulations to investigate the structure of dark halos in the standard cold dark matter cosmogony. Halos are excised from simulations of cosmologically representative regions and are resimulated individually at high resolution. We study objects with masses ranging from those of dwarf galaxy halos to those of rich galaxy clusters. The spherically averaged density profiles of all our halos can be fitted over two decades in radius by scaling a simple \"universal\" profile. The characteristic over- density of a halo, or equivalently its concentration, correlates strongly with halo mass in a way that reflects the mass dependence of the epoch of halo formation. Halo profiles are approximately isothermal over a large range in radii but are significantly shallower than r -2 near the center and steeper than r<SUP>-2</SUP> near the virial radius. Matching the observed rotation curves of disk galaxies requires disk mass-to-light ratios to increase systematically with luminosity. Further, it suggests that the halos of bright galaxies depend only weakly on galaxy luminosity and have circular velocities significantly lower than the disk rotation speed. This may explain why luminosity and dynamics are uncorrelated in observed samples of binary galaxies and of satellite/spiral systems. For galaxy clusters, our halo models are consistent both with the presence of giant arcs and with the observed structure of the intracluster medium, and they suggest a simple explanation for the disparate estimates of cluster core radii found by previous authors. Our results also highlight two shortcomings of the CDM model. CDM halos are too concentrated to be consistent with the halo parameters inferred for dwarf irregulars, and the predicted abundance of galaxy halos is larger than the observed abundance of galaxies. The first problem may imply that the core structure of dwarf galaxies was altered by the galaxy formation process, and the second problem may imply that galaxies failed to form (or remain undetected) in many dark halos.", "database": ["astronomy"], "keywords": ["COSMOLOGY: THEORY", "COSMOLOGY: DARK MATTER", "GALAXIES: HALOS", "METHODS: NUMERICAL", "Astrophysics"], "year": "1996", "doctype": "article", "citation_count": 8176, "domain_category": "astronomy"}
{"bibcode": "2018A&A...616A...1G", "title": "Gaia Data Release 2. Summary of the contents and survey properties", "abstract": "Context. We present the second Gaia data release, Gaia DR2, consisting of astrometry, photometry, radial velocities, and information on astrophysical parameters and variability, for sources brighter than magnitude 21. In addition epoch astrometry and photometry are provided for a modest sample of minor planets in the solar system. <BR /> Aims: A summary of the contents of Gaia DR2 is presented, accompanied by a discussion on the differences with respect to Gaia DR1 and an overview of the main limitations which are still present in the survey. Recommendations are made on the responsible use of Gaia DR2 results. <BR /> Methods: The raw data collected with the Gaia instruments during the first 22 months of the mission have been processed by the Gaia Data Processing and Analysis Consortium (DPAC) and turned into this second data release, which represents a major advance with respect to Gaia DR1 in terms of completeness, performance, and richness of the data products. <BR /> Results: Gaia DR2 contains celestial positions and the apparent brightness in G for approximately 1.7 billion sources. For 1.3 billion of those sources, parallaxes and proper motions are in addition available. The sample of sources for which variability information is provided is expanded to 0.5 million stars. This data release contains four new elements: broad-band colour information in the form of the apparent brightness in the G<SUB>BP</SUB> (330-680 nm) and G<SUB>RP</SUB> (630-1050 nm) bands is available for 1.4 billion sources; median radial velocities for some 7 million sources are presented; for between 77 and 161 million sources estimates are provided of the stellar effective temperature, extinction, reddening, and radius and luminosity; and for a pre-selected list of 14 000 minor planets in the solar system epoch astrometry and photometry are presented. Finally, Gaia DR2 also represents a new materialisation of the celestial reference frame in the optical, the Gaia-CRF2, which is the first optical reference frame based solely on extragalactic sources. There are notable changes in the photometric system and the catalogue source list with respect to Gaia DR1, and we stress the need to consider the two data releases as independent. <BR /> Conclusions: Gaia DR2 represents a major achievement for the Gaia mission, delivering on the long standing promise to provide parallaxes and proper motions for over 1 billion stars, and representing a first step in the availability of complementary radial velocity and source astrophysical information for a sample of stars in the Gaia survey which covers a very substantial fraction of the volume of our galaxy.", "database": ["astronomy"], "keywords": ["catalogs", "astrometry", "techniques: radial velocities", "stars: fundamental parameters", "stars: variables: general", "minor planets", "asteroids: general", "Astrophysics - Astrophysics of Galaxies", "Astrophysics - Instrumentation and Methods for Astrophysics"], "year": "2018", "doctype": "article", "citation_count": 8040, "domain_category": "astronomy"}
{"bibcode": "2007ApJS..170..377S", "title": "Three-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Implications for Cosmology", "abstract": "A simple cosmological model with only six parameters (matter density, Ω<SUB>m</SUB>h<SUP>2</SUP>, baryon density, Ω<SUB>b</SUB>h<SUP>2</SUP>, Hubble constant, H<SUB>0</SUB>, amplitude of fluctuations, σ<SUB>8</SUB>, optical depth, τ, and a slope for the scalar perturbation spectrum, n<SUB>s</SUB>) fits not only the 3 year WMAP temperature and polarization data, but also small-scale CMB data, light element abundances, large-scale structure observations, and the supernova luminosity/distance relationship. Using WMAP data only, the best-fit values for cosmological parameters for the power-law flat Λ cold dark matter (ΛCDM) model are (Ω<SUB>m</SUB>h<SUP>2</SUP>,Ω<SUB>b</SUB>h<SUP>2</SUP>,h,n<SUB>s</SUB>,τ,σ<SUB>8</SUB>)=(0.1277<SUP>+0.0080</SUP><SUB>-0.0079</SUB>,0.02229+/-0.00073,0.732<SUP>+0.031</SUP><SUB>-0.032</SUB>,0.958+/-0.016,0.089+/-0.030,0.761<SUP>+0.049</SUP><SUB>-0.048</SUB>). The 3 year data dramatically shrink the allowed volume in this six-dimensional parameter space. Assuming that the primordial fluctuations are adiabatic with a power-law spectrum, the WMAP data alone require dark matter and favor a spectral index that is significantly less than the Harrison-Zel'dovich-Peebles scale-invariant spectrum (n<SUB>s</SUB>=1, r=0). Adding additional data sets improves the constraints on these components and the spectral slope. For power-law models, WMAP data alone puts an improved upper limit on the tensor-to-scalar ratio, r<SUB>0.002</SUB>&lt;0.65 (95% CL) and the combination of WMAP and the lensing-normalized SDSS galaxy survey implies r<SUB>0.002</SUB>&lt;0.30 (95% CL). Models that suppress large-scale power through a running spectral index or a large-scale cutoff in the power spectrum are a better fit to the WMAP and small-scale CMB data than the power-law ΛCDM model; however, the improvement in the fit to the WMAP data is only Δχ<SUP>2</SUP>=3 for 1 extra degree of freedom. Models with a running-spectral index are consistent with a higher amplitude of gravity waves. In a flat universe, the combination of WMAP and the Supernova Legacy Survey (SNLS) data yields a significant constraint on the equation of state of the dark energy, w=-0.967<SUP>+0.073</SUP><SUB>-0.072</SUB>. If we assume w=-1, then the deviations from the critical density, Ω<SUB>K</SUB>, are small: the combination of WMAP and the SNLS data implies Ω<SUB>k</SUB>=-0.011+/-0.012. The combination of WMAP 3 year data plus the HST Key Project constraint on H<SUB>0</SUB> implies Ω<SUB>k</SUB>=-0.014+/-0.017 and Ω<SUB>Λ</SUB>=0.716+/-0.055. Even if we do not include the prior that the universe is flat, by combining WMAP, large-scale structure, and supernova data, we can still put a strong constraint on the dark energy equation of state, w=-1.08+/-0.12. For a flat universe, the combination of WMAP and other astronomical data yield a constraint on the sum of the neutrino masses, Σm<SUB>ν</SUB>&lt;0.66 eV (95%CL). Consistent with the predictions of simple inflationary theories, we detect no significant deviations from Gaussianity in the CMB maps using Minkowski functionals, the bispectrum, trispectrum, and a new statistic designed to detect large-scale anisotropies in the fluctuations.", "database": ["astronomy"], "keywords": ["Cosmology: Cosmic Microwave Background", "Cosmology: Observations", "Astrophysics"], "year": "2007", "doctype": "article", "citation_count": 7572, "domain_category": "astronomy"}
{"bibcode": "2011ApJ...737..103S", "title": "Measuring Reddening with Sloan Digital Sky Survey Stellar Spectra and Recalibrating SFD", "abstract": "We present measurements of dust reddening using the colors of stars with spectra in the Sloan Digital Sky Survey. We measure reddening as the difference between the measured and predicted colors of a star, as derived from stellar parameters from the Sloan Extension for Galactic Understanding and Exploration Stellar Parameter Pipeline. We achieve uncertainties of 56, 34, 25, and 29 mmag in the colors u - g, g - r, r - i, and i - z, per star, though the uncertainty varies depending on the stellar type and the magnitude of the star. The spectrum-based reddening measurements confirm our earlier \"blue tip\" reddening measurements, finding reddening coefficients different by -3%, 1%, 1%, and 2% in u - g, g - r, r - i, and i - z from those found by the blue tip method, after removing a 4% normalization difference. These results prefer an R<SUB>V</SUB> = 3.1 Fitzpatrick reddening law to O'Donnell or Cardelli et al. reddening laws. We provide a table of conversion coefficients from the Schlegel et al. (SFD) maps of E(B - V) to extinction in 88 bandpasses for four values of R<SUB>V</SUB> , using this reddening law and the 14% recalibration of SFD first reported by Schlafly et al. and confirmed in this work.", "database": ["astronomy"], "keywords": ["dust", "extinction", "Galaxy: stellar content", "ISM: clouds", "Astrophysics - Galaxy Astrophysics"], "year": "2011", "doctype": "article", "citation_count": 6956, "domain_category": "astronomy"}
{"bibcode": "1996BAMS...77..437K", "title": "The NCEP/NCAR 40-Year Reanalysis Project.", "abstract": "The NCEP and NCAR are cooperating in a project (denoted \"reanalysis\") to produce a 40-year record of global analyses of atmospheric fields in support of the needs of the research and climate monitoring communities. This effort involves the recovery of land surface, ship, rawinsonde, pibal, aircraft, satellite, and other data; quality controlling and assimilating these data with a data assimilation system that is kept unchanged over the reanalysis period 1957-96. This eliminates perceived climate jumps associated with changes in the data assimilation system.The NCEP/NCAR 40-yr reanalysis uses a frozen state-of-the-art global data assimilation system and a database as complete as possible. The data assimilation and the model used are identical to the global system implemented operationally at the NCEP on 11 January 1995, except that the horizontal resolution is T62 (about 210 km). The database has been enhanced with many sources of observations not available in real time for operations, provided by different countries and organizations. The system has been designed with advanced quality control and monitoring components, and can produce 1 mon of reanalysis per day on a Cray YMP/8 supercomputer. Different types of output archives are being created to satisfy different user needs, including a \"quick look\" CD-ROM (one per year) with six tropospheric and stratospheric fields available twice daily, as well as surface, top-of-the-atmosphere, and isentropic fields. Reanalysis information and selected output is also available on-line via the Internet (http//:nic.fb4.noaa.gov:8000). A special CD-ROM, containing 13 years of selected observed, daily, monthly, and climatological data from the NCEP/NCAR Re-analysis, is included with this issue. Output variables are classified into four classes, depending on the degree to which they are influenced by the observations and/or the model. For example, \"C\" variables (such as precipitation and surface fluxes) are completely determined by the model during the data assimilation and should be used with caution. Nevertheless, a comparison of these variables with observations and with several climatologies shows that they generally contain considerable useful information. Eight-day forecasts, produced every 5 days, should be useful for predictability studies and for monitoring the quality of the observing systems.The 40 years of reanalysis (1957-96) should be completed in early 1997. A continuation into the future through an identical Climate Data Assimilation System will allow researchers to reliably compare recent anomalies with those in earlier decades. Since changes in the observing systems will inevitably produce perceived changes in the climate, parallel reanalyses (at least 1 year long) will be generated for the periods immediately after the introduction of new observing systems, such as new types of satellite data.NCEP plans currently call for an updated reanalysis using a state-of-the-art system every five years or so. The successive reanalyses will be greatly facilitated by the generation of the comprehensive database in the present reanalysis.", "database": ["physics", "earth science"], "keywords": [], "year": "1996", "doctype": "article", "citation_count": 22281, "domain_category": "earth_science"}
{"bibcode": "2011QJRMS.137..553D", "title": "The ERA-Interim reanalysis: configuration and performance of the data assimilation system", "abstract": "ERA-Interim is the latest global atmospheric reanalysis produced by the European Centre for Medium-Range Weather Forecasts (ECMWF). The ERA-Interim project was conducted in part to prepare for a new atmospheric reanalysis to replace ERA-40, which will extend back to the early part of the twentieth century. This article describes the forecast model, data assimilation method, and input datasets used to produce ERA-Interim, and discusses the performance of the system. Special emphasis is placed on various difficulties encountered in the production of ERA-40, including the representation of the hydrological cycle, the quality of the stratospheric circulation, and the consistency in time of the reanalysed fields. We provide evidence for substantial improvements in each of these aspects. We also identify areas where further work is needed and describe opportunities and objectives for future reanalysis projects at ECMWF. Copyright", "database": ["physics", "earth science"], "keywords": ["ERA-40", "4D-Var", "hydrological cycle", "stratospheric circulation", "observations", "forecast model"], "year": "2011", "doctype": "article", "citation_count": 19199, "domain_category": "earth_science"}
{"bibcode": "2020QJRMS.146.1999H", "title": "The ERA5 global reanalysis", "abstract": "Within the Copernicus Climate Change Service (C3S), ECMWF is producing the ERA5 reanalysis which, once completed, will embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. This new reanalysis replaces the ERA-Interim reanalysis (spanning 1979 onwards) which was started in 2006. ERA5 is based on the Integrated Forecasting System (IFS) Cy41r2 which was operational in 2016. ERA5 thus benefits from a decade of developments in model physics, core dynamics and data assimilation. In addition to a significantly enhanced horizontal resolution of 31 km, compared to 80 km for ERA-Interim, ERA5 has hourly output throughout, and an uncertainty estimate from an ensemble (3-hourly at half the horizontal resolution). This paper describes the general set-up of ERA5, as well as a basic evaluation of characteristics and performance, with a focus on the dataset from 1979 onwards which is currently publicly available. Re-forecasts from ERA5 analyses show a gain of up to one day in skill with respect to ERA-Interim. Comparison with radiosonde and PILOT data prior to assimilation shows an improved fit for temperature, wind and humidity in the troposphere, but not the stratosphere. A comparison with independent buoy data shows a much improved fit for ocean wave height. The uncertainty estimate reflects the evolution of the observing systems used in ERA5. The enhanced temporal and spatial resolution allows for a detailed evolution of weather systems. For precipitation, global-mean correlation with monthly-mean GPCP data is increased from 67% to 77%. In general, low-frequency variability is found to be well represented and from 10 hPa downwards general patterns of anomalies in temperature match those from the ERA-Interim, MERRA-2 and JRA-55 reanalyses.", "database": ["physics", "earth science"], "keywords": ["climate reanalysis", "Copernicus Climate Change Service", "data assimilation", "ERA5", "historical observations"], "year": "2020", "doctype": "article", "citation_count": 18061, "domain_category": "earth_science"}
{"bibcode": "1989GSLSP..42..313S", "title": "Chemical and isotopic systematics of oceanic basalts: implications for mantle composition and processes", "abstract": "Trace-element data for mid-ocean ridge basalts (MORBs) and ocean island basalts (OIB) are used to formulate chemical systematics for oceanic basalts. The data suggest that the order of trace-element incompatibility in oceanic basalts is Cs ≈ Rb ≈ (≈ Tl) ≈ Ba(≈ W) &gt; Th &gt; U ≈ Nb = Ta ≈ K &gt; La &gt; Ce ≈ Pb &gt; Pr (≈ Mo) ≈ Sr &gt; P ≈ Nd (&gt; F) &gt; Zr = Hf ≈ Sm &gt; Eu ≈ Sn (≈ Sb) ≈ Ti &gt; Dy ≈ (Li) &gt; Ho = Y &gt; Yb. This rule works in general and suggests that the overall fractionation processes operating during magma generation and evolution are relatively simple, involving no significant change in the environment of formation for MORBs and OIBs. In detail, minor differences in element ratios correlate with the isotopic characteristics of different types of OIB components (HIMU, EM, MORB). These systematics are interpreted in terms of partial-melting conditions, variations in residual mineralogy, involvement of subducted sediment, recycling of oceanic lithosphere and processes within the low velocity zone. Niobium data indicate that the mantle sources of MORB and OIB are not exact complementary reservoirs to the continental crust. Subduction of oceanic crust or separation of refractory eclogite material from the former oceanic crust into the lower mantle appears to be required. The negative europium anomalies observed in some EM-type OIBs and the systematics of their key element ratios suggest the addition of a small amount (⩽1% or less) of subducted sediment to their mantle sources. However, a general lack of a crustal signature in OIBs indicates that sediment recycling has not been an important process in the convecting mantle, at least not in more recent times (⩽2 Ga). Upward migration of silica-undersaturated melts from the low velocity zone can generate an enriched reservoir in the continental and oceanic lithospheric mantle. We propose that the HIMU type (eg St Helena) OIB component can be generated in this way. This enriched mantle can be re-introduced into the convective mantle by thermal erosion of the continental lithosphere and by the recycling of the enriched oceanic lithosphere back into the mantle.", "database": ["physics", "earth science"], "keywords": [], "year": "1989", "doctype": "article", "citation_count": 12350, "domain_category": "earth_science"}
{"bibcode": "1995ChGeo.120..223M", "title": "The composition of the Earth", "abstract": "Compositional models of the Earth are critically dependent on three main sources of information: the seismic profile of the Earth and its interpretation, comparisons between primitive meteorites and the solar nebula composition, and chemical and petrological models of peridotite-basalt melting relationships. Whereas a family of compositional models for the Earth are permissible based on these methods, the model that is most consistent with the seismological and geodynamic structure of the Earth comprises an upper and lower mantle of similar composition, an FeNi core having between 5% and 15% of a low-atomic-weight element, and a mantle which, when compared to CI carbonaceous chondrites, is depleted in Mg and Si relative to the refractory lithophile elements. <P />The absolute and relative abundances of the refractory elements in carbonaceous, ordinary, and enstatite chondritic meteorites are compared. The bulk composition of an average CI carbonaceous chondrite is defined from previous compilations and from the refractory element compositions of different groups of chondrites. The absolute uncertainties in their refractory element compositions are evaluated by comparing ratios of these elements. These data are then used to evaluate existing models of the composition of the Silicate Earth. <P />The systematic behavior of major and trace elements during differentiation of the mantle is used to constrain the Silicate Earth composition. Seemingly fertile peridotites have experienced a previous melting event that must be accounted for when developing these models. The approach taken here avoids unnecessary assumptions inherent in several existing models, and results in an internally consistent Silicate Earth composition having chondritic proportions of the refractory lithophile elements at ∼ 2.75 times that in CI carbonaceous chondrites. Element ratios in peridotites, komatiites, basalts and various crustal rocks are used to assess the abundances of both non-lithophile and non-refractory elements in the Silicate Earth. These data provide insights into the accretion processes of the Earth, the chemical evolution of the Earth's mantle, the effect of core formation, and indicate negligible exchange between the core and mantle throughout the geologic record (the last 3.5 Ga). <P />The composition of the Earth's core is poorly constrained beyond its major constituents (i.e. an FeNi alloy). Density contrasts between the inner and outer core boundary are used to suggest the presence (∼ 10 ± 5%) of a light element or a combination of elements (e.g., O, S, Si) in the outer core. The core is the dominant repository of siderophile elements in the Earth. The limits of our understanding of the core's composition (including the light-element component) depend on models of core formation and the class of chondritic meteorites we have chosen when constructing models of the bulk Earth's composition. <P />The Earth has a bulk Fe / Al of ∼ 20 ± 2, established by assuming that the Earth's budget of Al is stored entirely within the Silicate Earth and Fe is partitioned between the Silicate Earth (∼ 14%) and the core (∼ 86%). Chondritic meteorites display a range of Fe / Al ratios, with many having a value close to 20. A comparison of the bulk composition of the Earth and chondritic meteorites reveals both similarities and differences, with the Earth being more strongly depleted in the more volatile elements. There is no group of meteorites that has a bulk composition matching that of the Earth's.", "database": ["physics", "earth science"], "keywords": [], "year": "1995", "doctype": "article", "citation_count": 10964, "domain_category": "earth_science"}
{"bibcode": "2005IJCli..25.1965H", "title": "Very high resolution interpolated climate surfaces for global land areas", "abstract": "We developed interpolated climate surfaces for global land areas (excluding Antarctica) at a spatial resolution of 30 arc s (often referred to as 1-km spatial resolution). The climate elements considered were monthly precipitation and mean, minimum, and maximum temperature. Input data were gathered from a variety of sources and, where possible, were restricted to records from the 1950-2000 period. We used the thin-plate smoothing spline algorithm implemented in the ANUSPLIN package for interpolation, using latitude, longitude, and elevation as independent variables. We quantified uncertainty arising from the input data and the interpolation by mapping weather station density, elevation bias in the weather stations, and elevation variation within grid cells and through data partitioning and cross validation. Elevation bias tended to be negative (stations lower than expected) at high latitudes but positive in the tropics. Uncertainty is highest in mountainous and in poorly sampled areas. Data partitioning showed high uncertainty of the surfaces on isolated islands, e.g. in the Pacific. Aggregating the elevation and climate data to 10 arc min resolution showed an enormous variation within grid cells, illustrating the value of high-resolution surfaces. A comparison with an existing data set at 10 arc min resolution showed overall agreement, but with significant variation in some regions. A comparison with two high-resolution data sets for the United States also identified areas with large local differences, particularly in mountainous areas. Compared to previous global climatologies, ours has the following advantages: the data are at a higher spatial resolution (400 times greater or more); more weather station records were used; improved elevation data were used; and more information about spatial patterns of uncertainty in the data is available. Owing to the overall low density of available climate stations, our surfaces do not capture of all variation that may occur at a resolution of 1 km, particularly of precipitation in mountainous areas. In future work, such variation might be captured through knowledge-based methods and inclusion of additional co-variates, particularly layers obtained through remote sensing.", "database": ["physics", "earth science"], "keywords": ["ANUSPLIN", "climate", "error", "GIS", "interpolation", "temperature", "precipitation", "uncertainty"], "year": "2005", "doctype": "article", "citation_count": 10548, "domain_category": "earth_science"}
{"bibcode": "2003JGRD..108.4407R", "title": "Global analyses of sea surface temperature, sea ice, and night marine air temperature since the late nineteenth century", "abstract": "We present the Met Office Hadley Centre's sea ice and sea surface temperature (SST) data set, HadISST1, and the nighttime marine air temperature (NMAT) data set, HadMAT1. HadISST1 replaces the global sea ice and sea surface temperature (GISST) data sets and is a unique combination of monthly globally complete fields of SST and sea ice concentration on a 1° latitude-longitude grid from 1871. The companion HadMAT1 runs monthly from 1856 on a 5° latitude-longitude grid and incorporates new corrections for the effect on NMAT of increasing deck (and hence measurement) heights. HadISST1 and HadMAT1 temperatures are reconstructed using a two-stage reduced-space optimal interpolation procedure, followed by superposition of quality-improved gridded observations onto the reconstructions to restore local detail. The sea ice fields are made more homogeneous by compensating satellite microwave-based sea ice concentrations for the impact of surface melt effects on retrievals in the Arctic and for algorithm deficiencies in the Antarctic and by making the historical in situ concentrations consistent with the satellite data. SSTs near sea ice are estimated using statistical relationships between SST and sea ice concentration. HadISST1 compares well with other published analyses, capturing trends in global, hemispheric, and regional SST well, containing SST fields with more uniform variance through time and better month-to-month persistence than those in GISST. HadMAT1 is more consistent with SST and with collocated land surface air temperatures than previous NMAT data sets.", "database": ["physics", "earth science"], "keywords": ["Global Change: Atmosphere (0315", "0325)", "Global Change: Oceans (4203)", "Hydrology: Glaciology (1863)", "Meteorology and Atmospheric Dynamics: Ocean/atmosphere interactions (0312", "4504)", "sea surface temperature", "sea ice", "night marine air temperature", "climate data reconstruction", "bias correction", "climate change"], "year": "2003", "doctype": "article", "citation_count": 8242, "domain_category": "earth_science"}
{"bibcode": "2017IJCli..37.4302F", "title": "WorldClim 2: new 1-km spatial resolution climate surfaces for global land areas", "abstract": "We created a new dataset of spatially interpolated monthly climate data for global land areas at a very high spatial resolution (approximately 1 km<SUP>2</SUP>). We included monthly temperature (minimum, maximum and average), precipitation, solar radiation, vapour pressure and wind speed, aggregated across a target temporal range of 1970─2000, using data from between 9000 and 60 000 weather stations. Weather station data were interpolated using thin-plate splines with covariates including elevation, distance to the coast and three satellite-derived covariates: maximum and minimum land surface temperature as well as cloud cover, obtained with the MODIS satellite platform. Interpolation was done for 23 regions of varying size depending on station density. Satellite data improved prediction accuracy for temperature variables 5─15% (0.07─0.17 °C), particularly for areas with a low station density, although prediction error remained high in such regions for all climate variables. Contributions of satellite covariates were mostly negligible for the other variables, although their importance varied by region. In contrast to the common approach to use a single model formulation for the entire world, we constructed the final product by selecting the best performing model for each region and variable. Global cross-validation correlations were ≥ 0.99 for temperature and humidity, 0.86 for precipitation and 0.76 for wind speed. The fact that most of our climate surface estimates were only marginally improved by use of satellite covariates highlights the importance having a dense, high-quality network of climate station data.", "database": ["physics", "earth science"], "keywords": ["interpolation", "climate surfaces", "WorldClim", "MODIS", "land surface temperature", "cloud cover", "solar radiation", "wind speed", "vapour pressure"], "year": "2017", "doctype": "article", "citation_count": 8207, "domain_category": "earth_science"}
{"bibcode": "2017RSEnv.202...18G", "title": "Google Earth Engine: Planetary-scale geospatial analysis for everyone", "abstract": "Google Earth Engine is a cloud-based platform for planetary-scale geospatial analysis that brings Google's massive computational capabilities to bear on a variety of high-impact societal issues including deforestation, drought, disaster, disease, food security, water management, climate monitoring and environmental protection. It is unique in the field as an integrated platform designed to empower not only traditional remote sensing scientists, but also a much wider audience that lacks the technical capacity needed to utilize traditional supercomputers or large-scale commodity cloud computing resources.", "database": ["physics", "earth science"], "keywords": ["Cloud computing", "Big data", "Analysis", "Platform", "Data democratization", "Earth Engine"], "year": "2017", "doctype": "article", "citation_count": 8185, "domain_category": "earth_science"}
{"bibcode": "2016GMD.....9.1937E", "title": "Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization", "abstract": "By coordinating the design and distribution of global climate model simulations of the past, current, and future climate, the Coupled Model Intercomparison Project (CMIP) has become one of the foundational elements of climate science. However, the need to address an ever-expanding range of scientific questions arising from more and more research communities has made it necessary to revise the organization of CMIP. After a long and wide community consultation, a new and more federated structure has been put in place. It consists of three major elements: (1) a handful of common experiments, the DECK (Diagnostic, Evaluation and Characterization of Klima) and CMIP historical simulations (1850-near present) that will maintain continuity and help document basic characteristics of models across different phases of CMIP; (2) common standards, coordination, infrastructure, and documentation that will facilitate the distribution of model outputs and the characterization of the model ensemble; and (3) an ensemble of CMIP-Endorsed Model Intercomparison Projects (MIPs) that will be specific to a particular phase of CMIP (now CMIP6) and that will build on the DECK and CMIP historical simulations to address a large range of specific questions and fill the scientific gaps of the previous CMIP phases. The DECK and CMIP historical simulations, together with the use of CMIP data standards, will be the entry cards for models participating in CMIP. Participation in CMIP6-Endorsed MIPs by individual modelling groups will be at their own discretion and will depend on their scientific interests and priorities. With the Grand Science Challenges of the World Climate Research Programme (WCRP) as its scientific backdrop, CMIP6 will address three broad questions: <BR /><BR /> - How does the Earth system respond to forcing?<BR /><BR /> - What are the origins and consequences of systematic model biases? <BR /><BR /> - How can we assess future climate changes given internal climate variability, predictability, and uncertainties in scenarios?<BR /><BR /> This CMIP6 overview paper presents the background and rationale for the new structure of CMIP, provides a detailed description of the DECK and CMIP6 historical simulations, and includes a brief introduction to the 21 CMIP6-Endorsed MIPs.", "database": ["physics", "earth science"], "keywords": [], "year": "2016", "doctype": "article", "citation_count": 7587, "domain_category": "earth_science"}
{"bibcode": "2007HESS...11.1633P", "title": "Updated world map of the Köppen-Geiger climate classification", "abstract": "Although now over 100 years old, the classification of climate originally formulated by Wladimir Köppen and modified by his collaborators and successors, is still in widespread use. It is widely used in teaching school and undergraduate courses on climate. It is also still in regular use by researchers across a range of disciplines as a basis for climatic regionalisation of variables and for assessing the output of global climate models. Here we have produced a new global map of climate using the Köppen-Geiger system based on a large global data set of long-term monthly precipitation and temperature station time series. Climatic variables used in the Köppen-Geiger system were calculated at each station and interpolated between stations using a two-dimensional (latitude and longitude) thin-plate spline with tension onto a 0.1°×0.1° grid for each continent. We discuss some problems in dealing with sites that are not uniquely classified into one climate type by the Köppen-Geiger system and assess the outcomes on a continent by continent basis. Globally the most common climate type by land area is BWh (14.2%, Hot desert) followed by Aw (11.5%, Tropical savannah). The updated world Köppen-Geiger climate map is freely available electronically in the Supplementary Material Section.", "database": ["physics", "earth science"], "keywords": [], "year": "2007", "doctype": "article", "citation_count": 7264, "domain_category": "earth_science"}
{"bibcode": "1997JGR...10216663M", "title": "Radiative transfer for inhomogeneous atmospheres: RRTM, a validated correlated-k model for the longwave", "abstract": "A rapid and accurate radiative transfer model (RRTM) for climate applications has been developed and the results extensively evaluated. The current version of RRTM calculates fluxes and cooling rates for the longwave spectral region (10-3000 cm<SUP>-1</SUP>) for an arbitrary clear atmosphere. The molecular species treated in the model are water vapor, carbon dioxide, ozone, methane, nitrous oxide, and the common halocarbons. The radiative transfer in RRTM is performed using the correlated-k method: the k distributions are attained directly from the LBLRTM line-by-line model, which connects the absorption coefficients used by RRTM to high-resolution radiance validations done with observations. Refined methods have been developed for treating bands containing gases with overlapping absorption, for the determination of values of the Planck function appropriate for use in the correlated-k approach, and for the inclusion of minor absorbing species in a band. The flux and cooling rate results of RRTM are linked to measurement through the use of LBLRTM, which has been substantially validated with observations. Validations of RRTM using LBLRTM have been performed for the midlatitude summer, tropical, midlatitude winter, subarctic winter, and four atmospheres from the Spectral Radiance Experiment campaign. On the basis of these validations the longwave accuracy of RRTM for any atmosphere is as follows: 0.6 W m<SUP>-2</SUP> (relative to LBLRTM) for net flux in each band at all altitudes, with a total (10-3000 cm<SUP>-1</SUP>) error of less than 1.0 W m<SUP>-2</SUP> at any altitude; 0.07 K d<SUP>-1</SUP> for total cooling rate error in the troposphere and lower stratosphere, and 0.75 K d<SUP>-1</SUP> in the upper stratosphere and above. Other comparisons have been performed on RRTM using LBLRTM to gauge its sensitivity to changes in the abundance of specific species, including the halocarbons and carbon dioxide. The radiative forcing due to doubling the concentration of carbon dioxide is attained with an accuracy of 0.24 W m<SUP>-2</SUP>, an error of less than 5%. The speed of execution of RRTM compares favorably with that of other rapid radiation models, indicating that the model is suitable for use in general circulation models.", "database": ["physics", "earth science"], "keywords": ["Atmospheric Composition and Structure: Transmission and scattering of radiation", "Meteorology and Atmospheric Dynamics: Radiative processes"], "year": "1997", "doctype": "article", "citation_count": 6093, "domain_category": "earth_science"}
{"bibcode": "2001JGR...106.7183T", "title": "Summarizing multiple aspects of model performance in a single diagram", "abstract": "A diagram has been devised that can provide a concise statistical summary of how well patterns match each other in terms of their correlation, their root-mean-square difference, and the ratio of their variances. Although the form of this diagram is general, it is especially useful in evaluating complex models, such as those used to study geophysical phenomena. Examples are given showing that the diagram can be used to summarize the relative merits of a collection of different models or to track changes in performance of a model as it is modified. Methods are suggested for indicating on these diagrams the statistical significance of apparent differences and the degree to which observational uncertainty and unforced internal variability limit the expected agreement between model-simulated and observed behaviors. The geometric relationship between the statistics plotted on the diagram also provides some guidance for devising skill scores that appropriately weight among the various measures of pattern correspondence.", "database": ["physics", "earth science"], "keywords": ["Meteorology and Atmospheric Dynamics: Theoretical modeling", "Meteorology and Atmospheric Dynamics: Instruments and techniques", "General or Miscellaneous: Techniques applicable in three or more fields"], "year": "2001", "doctype": "article", "citation_count": 5767, "domain_category": "earth_science"}
{"bibcode": "2005QJRMS.131.2961U", "title": "The ERA-40 re-analysis", "abstract": "ERA-40 is a re-analysis of meteorological observations from September 1957 to August 2002 produced by the European Centre for Medium-Range Weather Forecasts (ECMWF) in collaboration with many institutions. The observing system changed considerably over this re-analysis period, with assimilable data provided by a succession of satellite-borne instruments from the 1970s onwards, supplemented by increasing numbers of observations from aircraft, ocean-buoys and other surface platforms, but with a declining number of radiosonde ascents since the late 1980s. The observations used in ERA-40 were accumulated from many sources. The first part of this paper describes the data acquisition and the principal changes in data type and coverage over the period. It also describes the data assimilation system used for ERA-40. This benefited from many of the changes introduced into operational forecasting since the mid-1990s, when the systems used for the 15-year ECMWF re-analysis (ERA-15) and the National Centers for Environmental Prediction/National Center for Atmospheric Research (NCEP/NCAR) re-analysis were implemented. Several of the improvements are discussed. General aspects of the production of the analyses are also summarized. A number of results indicative of the overall performance of the data assimilation system, and implicitly of the observing system, are presented and discussed. The comparison of background (short-range) forecasts and analyses with observations, the consistency of the global mass budget, the magnitude of differences between analysis and background fields and the accuracy of medium-range forecasts run from the ERA-40 analyses are illustrated. Several results demonstrate the marked improvement that was made to the observing system for the southern hemisphere in the 1970s, particularly towards the end of the decade. In contrast, the synoptic quality of the analysis for the northern hemisphere is sufficient to provide forecasts that remain skilful well into the medium range for all years. Two particular problems are also examined: excessive precipitation over tropical oceans and a too strong Brewer-Dobson circulation, both of which are pronounced in later years. Several other aspects of the quality of the re-analyses revealed by monitoring and validation studies are summarized. Expectations that the 'second-generation' ERA-40 re-analysis would provide products that are better than those from the firstgeneration ERA-15 and NCEP/NCAR re-analyses are found to have been met in most cases. © Royal Meteorological Society, 2005. The contributions of N. A. Rayner and R. W. Saunders are Crown copyright.", "database": ["physics", "earth science"], "keywords": ["Data assimilation", "Numerical weather prediction", "Observing system"], "year": "2005", "doctype": "article", "citation_count": 5499, "domain_category": "earth_science"}
{"bibcode": "1998RSEnv..66....1H", "title": "AERONET-A Federated Instrument Network and Data Archive for Aerosol Characterization", "abstract": "The concept and description of a remote sensing aerosol monitoring network initiated by NASA, developed to support NASA, CNES, and NASDA's Earth satellite systems under the name AERONET and expanded by national and international collaboration, is described. Recent development of weather-resistant automatic sun and sky scanning spectral radiometers enable frequent measurements of atmospheric aerosol optical properties and precipitable water at remote sites. Transmission of automatic measurements via the geostationary satellites GOES and METEOSATS' Data Collection Systems allows reception and processing in near real-time from approximately 75% of the Earth's surface and with the expected addition of GMS, the coverage will increase to 90% in 1998. NASA developed a UNIX-based near real-time processing, display and analysis system providing internet access to the emerging global database. Information on the system is available on the project homepage, http://spamer.gsfc.nasa.gov. The philosophy of an open access database, centralized processing and a user-friendly graphical interface has contributed to the growth of international cooperation for ground-based aerosol monitoring and imposes a standardization for these measurements. The system's automatic data acquisition, transmission, and processing facilitates aerosol characterization on local, regional, and global scales with applications to transport and radiation budget studies, radiative transfer-modeling and validation of satellite aerosol retrievals. This article discusses the operation and philosophy of the monitoring system, the precision and accuracy of the measuring radiometers, a brief description of the processing system, and access to the database.", "database": ["physics", "earth science"], "keywords": [], "year": "1998", "doctype": "article", "citation_count": 5262, "domain_category": "earth_science"}
{"bibcode": "2011ClCh..109....5V", "title": "The representative concentration pathways: an overview", "abstract": "This paper summarizes the development process and main characteristics of the Representative Concentration Pathways (RCPs), a set of four new pathways developed for the climate modeling community as a basis for long-term and near-term modeling experiments. The four RCPs together span the range of year 2100 radiative forcing values found in the open literature, i.e. from 2.6 to 8.5 W/m<SUP>2</SUP>. The RCPs are the product of an innovative collaboration between integrated assessment modelers, climate modelers, terrestrial ecosystem modelers and emission inventory experts. The resulting product forms a comprehensive data set with high spatial and sectoral resolutions for the period extending to 2100. Land use and emissions of air pollutants and greenhouse gases are reported mostly at a 0.5 × 0.5 degree spatial resolution, with air pollutants also provided per sector (for well-mixed gases, a coarser resolution is used). The underlying integrated assessment model outputs for land use, atmospheric emissions and concentration data were harmonized across models and scenarios to ensure consistency with historical observations while preserving individual scenario trends. For most variables, the RCPs cover a wide range of the existing literature. The RCPs are supplemented with extensions (Extended Concentration Pathways, ECPs), which allow climate modeling experiments through the year 2300. The RCPs are an important development in climate research and provide a potential foundation for further research and assessment, including emissions mitigation and impact analysis.", "database": ["physics", "earth science"], "keywords": ["Climate Policy", "Force Level", "Representative Concentration Pathway", "Integrate Assessment Model", "Mitigation Scenario"], "year": "2011", "doctype": "article", "citation_count": 5157, "domain_category": "earth_science"}
{"bibcode": "1997BAMS...78.1069M", "title": "A Pacific Interdecadal Climate Oscillation with Impacts on Salmon Production.", "abstract": "Evidence gleaned from the instrumental record of climate data identifies a robust, recurring pattern of ocean-atmosphere climate variability centered over the midlatitude North Pacific basin. Over the past century, the amplitude of this climate pattern has varied irregularly at interannual-to-interdecadal timescales. There is evidence of reversals in the prevailing polarity of the oscillation occurring around 1925, 1947, and 1977; the last two reversals correspond to dramatic shifts in salmon production regimes in the North Pacific Ocean. This climate pattern also affects coastal sea and continental surface air temperatures, as well as streamflow in major west coast river systems, from Alaska to California.", "database": ["physics", "earth science"], "keywords": [], "year": "1997", "doctype": "article", "citation_count": 5089, "domain_category": "earth_science"}
{"bibcode": "1978SSASJ..42..421L", "title": "Development of a DTPA Soil Test for Zinc, Iron, Manganese, and Copper", "abstract": "A DTPA soil test was developed to identify near-neutral and calcareous soils with insufficient available Zn, Fe, Mn, or Cu for maximum yields of crops. The extractant consists of 0.005M DTPA (diethylenetriaminepentaacetic acid), 0.1M triethanolamine, and 0.01M CaCl<SUB>2</SUB>, with a pH of 7.3. The soil test consists of shaking 10 g of air-dry soil with 20 ml of extractant for 2 hours. The leachate is filtered, and Zn, Fe, Mn, and Cu are measured in the filtrate by atomic absorption spectrophotometry. The soil test successfully separated 77 Colorado soils on the basis of crop response to Zn, Fe, and Mn fertilizers. Critical nutrient levels must be determined separately for each crop using standardized procedures for soil preparation, grinding, and extraction. The critical levels for corn using the procedures reported herein were: 0.8 ppm for Zn, 4.5 ppm for Fe, and tentatively 1.0 ppm for Mn, and 0.2 ppm for Cu. Development of the soil test was based, in part, on theoretical considerations. The extractant is buffered at pH 7.30 and contains CaCl<SUB>2</SUB> so that equilibrium with CaCO<SUB>3</SUB> is established at a CO<SUB>2</SUB> level about 10 times that of the atmosphere. Thus, the extractant precludes dissolution of CaCO<SUB>3</SUB> and the release of occluded nutrients which are normally not available to plants. DTPA was selected as the chelating agent because it can effectively extract all four micronutrient metals. Factors such as pH, concentration of chelating agent, time of shaking, and temperature of extraction affect the amount of micronutrients extracted and were adjusted for maximum overall effectiveness.", "database": ["physics", "earth science"], "keywords": [], "year": "1978", "doctype": "article", "citation_count": 5063, "domain_category": "earth_science"}
{"bibcode": "2000AREPS..28..211Y", "title": "Geologic Evolution of the Himalayan-Tibetan Orogen", "abstract": "A review of the geologic history of the Himalayan-Tibetan orogen suggests that at least 1400 km of north-south shortening has been absorbed by the orogen since the onset of the Indo-Asian collision at about 70 Ma. Significant crustal shortening, which leads to eventual construction of the Cenozoic Tibetan plateau, began more or less synchronously in the Eocene (50-40 Ma) in the Tethyan Himalaya in the south, and in the Kunlun Shan and the Qilian Shan some 1000-1400 km in the north. The Paleozoic and Mesozoic tectonic histories in the Himalayan-Tibetan orogen exerted a strong control over the Cenozoic strain history and strain distribution. The presence of widespread Triassic flysch complex in the Songpan-Ganzi-Hoh Xil and the Qiangtang terranes can be spatially correlated with Cenozoic volcanism and thrusting in central Tibet. The marked difference in seismic properties of the crust and the upper mantle between southern and central Tibet is a manifestation of both Mesozoic and Cenozoic tectonics. The former, however, has played a decisive role in localizing Tertiary contractional deformation, which in turn leads to the release of free water into the upper mantle and the lower crust of central Tibet, causing partial melting in the mantle lithosphere and the crust.", "database": ["astronomy", "earth science"], "keywords": ["OROGENIC DEVELOPMENT", "CONTINENTAL COLLISION", "HIMALAYA", "TIBETAN PLATEAU"], "year": "2000", "doctype": "article", "citation_count": 4997, "domain_category": "earth_science"}
{"bibcode": "1998JAWRA..34...73A", "title": "Large Area Hydrologic Modeling and Assessment Part i: Model DEVELOPMENT<SUP>1</SUP>", "abstract": "ABSTRACT: A conceptual, continuous time model called SWAT (Soil and Water Assessment Tool) was developed to assist water resource managers in assessing the impact of management on water supplies and nonpoint source pollution in watersheds and large river basins. The model is currently being utilized in several large area projects by EPA, NOAA, NRCS and others to estimate the off-site impacts of climate and management on water use, non-point source loadings, and pesticide contamination. Model development, operation, limitations, and assumptions are discussed and components of the model are described. In Part II, a GIS input/output interface is presented along with model validation on three basins within the Upper Trinity basin in Texas.", "database": ["physics", "earth science"], "keywords": ["simulation", "surface water hydrology", "erosion", "sedimentation", "nonpoint source pollution", "large area modeling", "plant growth", "agricultural land management"], "year": "1998", "doctype": "article", "citation_count": 4951, "domain_category": "earth_science"}
{"bibcode": "2007RvGeo..45.2004F", "title": "The Shuttle Radar Topography Mission", "abstract": "The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.", "database": ["physics", "earth science"], "keywords": ["Radio Science: Interferometry (1207", "1209", "1242)", "Hydrology: Geomorphology: general (1625)", "General or Miscellaneous: Instruments useful in three or more fields", "topography", "radar", "interferometry"], "year": "2007", "doctype": "article", "citation_count": 4897, "domain_category": "earth_science"}
{"bibcode": "1982RvGSP..20..851M", "title": "Development of a Turbulence Closure Model for Geophysical Fluid Problems (Paper 2R0808)", "abstract": "Applications of second-moment turbulent closure hypotheses to geophysical fluid problems have developed rapidly since 1973, when genuine predictive skill in coping with the effects of stratification was demonstrated. The purpose here is to synthesize and organize material that has appeared in a number of articles and add new useful material so that a complete (and improved) description of a turbulence model from conception to application is condensed in a single article. It is hoped that this will be a useful reference to users of the model for application to either atmospheric or oceanic boundary layers.", "database": ["astronomy", "physics", "earth science"], "keywords": ["Closure Law", "Geophysical Fluids", "Mathematical Models", "Turbulence Models", "Turbulent Flow", "Atmospheric Boundary Layer", "Computational Fluid Dynamics", "Moments", "Oceanography", "Shear Flow", "Stratified Flow", "Temperature Effects"], "year": "1982", "doctype": "article", "citation_count": 4863, "domain_category": "earth_science"}
{"bibcode": "2002BAMS...83.1631K", "title": "NCEP-DOE AMIP-II Reanalysis (R-2).", "abstract": "The NCEP-DOE Atmospheric Model Intercomparison Project (AMIP-II) reanalysis is a follow-on project to the \"50-year\" (1948-present) NCEP-NCAR Reanalysis Project. NCEP-DOE AMIP-II reanalysis covers the \"20-year\" satellite period of 1979 to the present and uses an updated forecast model, updated data assimilation system, improved diagnostic outputs, and fixes for the known processing problems of the NCEP-NCAR reanalysis. Only minor differences are found in the primary analysis variables such as free atmospheric geopotential height and winds in the Northern Hemisphere extratropics, while significant improvements upon NCEP-NCAR reanalysis are made in land surface parameters and land-ocean fluxes. This analysis can be used as a supplement to the NCEP-NCAR reanalysis especially where the original analysis has problems. The differences between the two analyses also provide a measure of uncertainty in current analyses.", "database": ["physics", "earth science"], "keywords": [], "year": "2002", "doctype": "article", "citation_count": 4708, "domain_category": "earth_science"}
{"bibcode": "2003TrGeo...3....1R", "title": "Composition of the Continental Crust", "abstract": "The Earth is an unusual planet in our solar system in having a bimodal topography that reflects the two distinct types of crust found on our planet. The low-lying oceanic crust is thin (∼7 km on average), composed of relatively dense rock types such as basalt and is young (≤200 Ma old) (see Chapter 3.13). In contrast, the high-standing continental crust is thick (∼40 km on average), is composed of highly diverse lithologies (virtually every rock type known on Earth) that yield an average intermediate or \"andesitic\" bulk composition (Taylor and McLennan (1985) and references therein), and contains the oldest rocks and minerals yet observed on Earth (currently the 4.0 Ga Acasta gneisses (Bowring and Williams, 1999) and 4.4 Ga detrital zircons from the Yilgarn Block, Western Australia (Wilde et al., 2001)), respectively. Thus, the continents preserve a rich geological history of our planet's evolution and understanding their origin is critical for understanding the origin and differentiation of the Earth.The origin of the continents has received wide attention within the geological community, with hundreds of papers and several books devoted to the topic (the reader is referred to the following general references for further reading: Taylor and McLennan (1985), Windley (1995), and Condie (1997). Knowledge of the age and composition of the continental crust is essential for understanding its origin. Patchett and Samson (Chapter 3.10) review the present-day age distribution of the continental crust and Kemp and Hawkesworth (Chapter 3.11) review secular evolution of crust composition. Moreover, to understand fully the origin and evolution of continents requires an understanding of not only the crust, but also the mantle lithosphere that formed more-or-less contemporaneously with the crust and translates with it as the continents move across the Earth's surface. The latter topic is reviewed in Chapter 2.05.This chapter reviews the present-day composition of the continental crust, the methods employed to derive these estimates, and the implications of the continental crust composition for the formation of the continents, Earth differentiation, and its geochemical inventories.", "database": ["astronomy", "physics", "earth science"], "keywords": [], "year": "2003", "doctype": "article", "citation_count": 4368, "domain_category": "earth_science"}
{"bibcode": "2014IJCli..34..623H", "title": "Updated high-resolution grids of monthly climatic observations ─ the CRU TS3.10 Dataset", "abstract": "This paper describes the construction of an updated gridded climate dataset (referred to as CRU TS3.10) from monthly observations at meteorological stations across the world's land areas. Station anomalies (from 1961 to 1990 means) were interpolated into 0.5° latitude/longitude grid cells covering the global land surface (excluding Antarctica), and combined with an existing climatology to obtain absolute monthly values. The dataset includes six mostly independent climate variables (mean temperature, diurnal temperature range, precipitation, wet-day frequency, vapour pressure and cloud cover). Maximum and minimum temperatures have been arithmetically derived from these. Secondary variables (frost day frequency and potential evapotranspiration) have been estimated from the six primary variables using well-known formulae. Time series for hemispheric averages and 20 large sub-continental scale regions were calculated (for mean, maximum and minimum temperature and precipitation totals) and compared to a number of similar gridded products. The new dataset compares very favourably, with the major deviations mostly in regions and/or time periods with sparser observational data. CRU TS3.10 includes diagnostics associated with each interpolated value that indicates the number of stations used in the interpolation, allowing determination of the reliability of values in an objective way. This gridded product will be publicly available, including the input station series (http://www.cru.uea.ac.uk/ and http://badc.nerc.ac.uk/data/cru/). © 2013 Royal Meteorological Society", "database": ["physics", "earth science"], "keywords": ["gridded climate data", "high resolution", "temperature", "precipitation"], "year": "2014", "doctype": "article", "citation_count": 4129, "domain_category": "earth_science"}
{"bibcode": "1997Natur.387..253C", "title": "The value of the world's ecosystem services and natural capital", "abstract": "The services of ecological systems and the natural capital stocks that produce them are critical to the functioning of the Earth's life-support system. They contribute to human welfare, both directly and indirectly, and therefore represent part of the total economic value of the planet. We have estimated the current economic value of 17 ecosystem services for 16 biomes, based on published studies and a few original calculations. For the entire biosphere, the value (most of which is outside the market) is estimated to be in the range of US$16-54 trillion (10<SUP>12</SUP>) per year, with an average of US$33 trillion per year. Because of the nature of the uncertainties, this must be considered a minimum estimate. Global gross national product total is around US$18 trillion per year.", "database": ["astronomy", "general"], "keywords": [], "year": "1997", "doctype": "article", "citation_count": 10433, "domain_category": "planetary_science"}
{"bibcode": "2005Sci...309..570F", "title": "Global Consequences of Land Use", "abstract": "Land use has generally been considered a local environmental issue, but it is becoming a force of global importance. Worldwide changes to forests, farmlands, waterways, and air are being driven by the need to provide food, fiber, water, and shelter to more than six billion people. Global croplands, pastures, plantations, and urban areas have expanded in recent decades, accompanied by large increases in energy, water, and fertilizer consumption, along with considerable losses of biodiversity. Such changes in land use have enabled humans to appropriate an increasing share of the planet's resources, but they also potentially undermine the capacity of ecosystems to sustain food production, maintain freshwater and forest resources, regulate climate and air quality, and ameliorate infectious diseases. We face the challenge of managing trade-offs between immediate human needs and maintaining the capacity of the biosphere to provide goods and services in the long term.", "database": ["astronomy", "general"], "keywords": ["ECOLOGY"], "year": "2005", "doctype": "article", "citation_count": 7525, "domain_category": "planetary_science"}
{"bibcode": "2016A&A...595A...1G", "title": "The Gaia mission", "abstract": "Gaia is a cornerstone mission in the science programme of the EuropeanSpace Agency (ESA). The spacecraft construction was approved in 2006, following a study in which the original interferometric concept was changed to a direct-imaging approach. Both the spacecraft and the payload were built by European industry. The involvement of the scientific community focusses on data processing for which the international Gaia Data Processing and Analysis Consortium (DPAC) was selected in 2007. Gaia was launched on 19 December 2013 and arrived at its operating point, the second Lagrange point of the Sun-Earth-Moon system, a few weeks later. The commissioning of the spacecraft and payload was completed on 19 July 2014. The nominal five-year mission started with four weeks of special, ecliptic-pole scanning and subsequently transferred into full-sky scanning mode. We recall the scientific goals of Gaia and give a description of the as-built spacecraft that is currently (mid-2016) being operated to achieve these goals. We pay special attention to the payload module, the performance of which is closely related to the scientific performance of the mission. We provide a summary of the commissioning activities and findings, followed by a description of the routine operational mode. We summarise scientific performance estimates on the basis of in-orbit operations. Several intermediate Gaia data releases are planned and the data can be retrieved from the Gaia Archive, which is available through the Gaia home page. <P /><A href=\"http://www.cosmos.esa.int/gaia\">http://www.cosmos.esa.int/gaia</A>", "database": ["astronomy"], "keywords": ["space vehicles: instruments", "Galaxy: structure", "astrometry", "parallaxes", "proper motions", "telescopes", "Astrophysics - Instrumentation and Methods for Astrophysics"], "year": "2016", "doctype": "article", "citation_count": 6693, "domain_category": "planetary_science"}
{"bibcode": "1981PASP...93....5B", "title": "Classification parameters for the emission-line spectra of extragalactic objects.", "abstract": "An investigation is made of the merits of various emission-line intensity ratios for classifying the spectra of extragalactic objects. It is shown empirically that several combinations of easily-measured lines can be used to separate objects into one of four categories according to the principal excitation mechanism: normal H II regions, planetary nebulae, objects photoionized by a power-law continuum, and objects excited by shock-wave heating. A two-dimensional quantitative classification scheme is suggested.", "database": ["astronomy"], "keywords": ["Astronomical Spectroscopy", "Emission Spectra", "Line Spectra", "Quasars", "Seyfert Galaxies", "Classifications", "H Ii Regions", "Photoionization", "Planetary Nebulae", "Shock Heating", "Astrophysics"], "year": "1981", "doctype": "article", "citation_count": 5167, "domain_category": "planetary_science"}
{"bibcode": "2011ApJS..192....3P", "title": "Modules for Experiments in Stellar Astrophysics (MESA)", "abstract": "Stellar physics and evolution calculations enable a broad range of research in astrophysics. Modules for Experiments in Stellar Astrophysics (MESA) is a suite of open source, robust, efficient, thread-safe libraries for a wide range of applications in computational stellar astrophysics. A one-dimensional stellar evolution module, MESAstar, combines many of the numerical and physics modules for simulations of a wide range of stellar evolution scenarios ranging from very low mass to massive stars, including advanced evolutionary phases. MESAstar solves the fully coupled structure and composition equations simultaneously. It uses adaptive mesh refinement and sophisticated timestep controls, and supports shared memory parallelism based on OpenMP. State-of-the-art modules provide equation of state, opacity, nuclear reaction rates, element diffusion data, and atmosphere boundary conditions. Each module is constructed as a separate Fortran 95 library with its own explicitly defined public interface to facilitate independent development. Several detailed examples indicate the extensive verification and testing that is continuously performed and demonstrate the wide range of capabilities that MESA possesses. These examples include evolutionary tracks of very low mass stars, brown dwarfs, and gas giant planets to very old ages; the complete evolutionary track of a 1 M <SUB>sun</SUB> star from the pre-main sequence (PMS) to a cooling white dwarf; the solar sound speed profile; the evolution of intermediate-mass stars through the He-core burning phase and thermal pulses on the He-shell burning asymptotic giant branch phase; the interior structure of slowly pulsating B Stars and Beta Cepheids; the complete evolutionary tracks of massive stars from the PMS to the onset of core collapse; mass transfer from stars undergoing Roche lobe overflow; and the evolution of helium accretion onto a neutron star. MESA can be downloaded from the project Web site (<A href=\"http://mesa.sourceforge.net/\">http://mesa.sourceforge.net/</A>).", "database": ["astronomy"], "keywords": ["methods: numerical", "stars: evolution", "stars: general", "Astrophysics - Solar and Stellar Astrophysics", "Astrophysics - Instrumentation and Methods for Astrophysics"], "year": "2011", "doctype": "article", "citation_count": 4170, "domain_category": "planetary_science"}
{"bibcode": "2023A&A...674A...1G", "title": "Gaia Data Release 3. Summary of the content and survey properties", "abstract": "Context. We present the third data release of the European Space Agency's Gaia mission, Gaia DR3. This release includes a large variety of new data products, notably a much expanded radial velocity survey and a very extensive astrophysical characterisation of Gaia sources. <BR /> Aims: We outline the content and the properties of Gaia DR3, providing an overview of the main improvements in the data processing in comparison with previous data releases (where applicable) and a brief discussion of the limitations of the data in this release. <BR /> Methods: The Gaia DR3 catalogue is the outcome of the processing of raw data collected with the Gaia instruments during the first 34 months of the mission by the Gaia Data Processing and Analysis Consortium. <BR /> Results: The Gaia DR3 catalogue contains the same source list, celestial positions, proper motions, parallaxes, and broad band photometry in the G, G<SUB>BP</SUB>, and G<SUB>RP</SUB> pass-bands already present in the Early Third Data Release, Gaia EDR3. Gaia DR3 introduces an impressive wealth of new data products. More than 33 million objects in the ranges G<SUB>RVS</SUB> &lt; 14 and 3100 &lt; T<SUB>eff</SUB> &lt; 14 500, have new determinations of their mean radial velocities based on data collected by Gaia. We provide G<SUB>RVS</SUB> magnitudes for most sources with radial velocities, and a line broadening parameter is listed for a subset of these. Mean Gaia spectra are made available to the community. The Gaia DR3 catalogue includes about 1 million mean spectra from the radial velocity spectrometer, and about 220 million low-resolution blue and red prism photometer BP/RP mean spectra. The results of the analysis of epoch photometry are provided for some 10 million sources across 24 variability types. Gaia DR3 includes astrophysical parameters and source class probabilities for about 470 million and 1500 million sources, respectively, including stars, galaxies, and quasars. Orbital elements and trend parameters are provided for some 800 000 astrometric, spectroscopic and eclipsing binaries. More than 150 000 Solar System objects, including new discoveries, with preliminary orbital solutions and individual epoch observations are part of this release. Reflectance spectra derived from the epoch BP/RP spectral data are published for about 60 000 asteroids. Finally, an additional data set is provided, namely the Gaia Andromeda Photometric Survey, consisting of the photometric time series for all sources located in a 5.5 degree radius field centred on the Andromeda galaxy. <BR /> Conclusions: This data release represents a major advance with respect to Gaia DR2 and Gaia EDR3 because of the unprecedented quantity, quality, and variety of source astrophysical data. To date this is the largest collection of all-sky spectrophotometry, radial velocities, variables, and astrophysical parameters derived from both low- and high-resolution spectra and includes a spectrophotometric and dynamical survey of SSOs of the highest accuracy. The non-single star content surpasses the existing data by orders of magnitude. The quasar host and galaxy light profile collection is the first such survey that is all sky and space based. The astrophysical information provided in Gaia DR3 will unleash the full potential of Gaia's exquisite astrometric, photometric, and radial velocity surveys.", "database": ["astronomy"], "keywords": ["techniques: photometric", "techniques: spectroscopic", "techniques: radial velocities", "catalogs", "astrometry", "parallaxes", "Astrophysics - Astrophysics of Galaxies"], "year": "2023", "doctype": "article", "citation_count": 4070, "domain_category": "planetary_science"}
{"bibcode": "2015JATIS...1a4003R", "title": "Transiting Exoplanet Survey Satellite (TESS)", "abstract": "The Transiting Exoplanet Survey Satellite (TESS) will search for planets transiting bright and nearby stars. TESS has been selected by NASA for launch in 2017 as an Astrophysics Explorer mission. The spacecraft will be placed into a highly elliptical 13.7-day orbit around the Earth. During its 2-year mission, TESS will employ four wide-field optical charge-coupled device cameras to monitor at least 200,000 main-sequence dwarf stars with I<SUB>C</SUB>≈4-13 for temporary drops in brightness caused by planetary transits. Each star will be observed for an interval ranging from 1 month to 1 year, depending mainly on the star's ecliptic latitude. The longest observing intervals will be for stars near the ecliptic poles, which are the optimal locations for follow-up observations with the James Webb Space Telescope. Brightness measurements of preselected target stars will be recorded every 2 min, and full frame images will be recorded every 30 min. TESS stars will be 10 to 100 times brighter than those surveyed by the pioneering Kepler mission. This will make TESS planets easier to characterize with follow-up observations. TESS is expected to find more than a thousand planets smaller than Neptune, including dozens that are comparable in size to the Earth. Public data releases will occur every 4 months, inviting immediate community-wide efforts to study the new planets. The TESS legacy will be a catalog of the nearest and brightest stars hosting transiting planets, which will endure as highly favorable targets for detailed investigations.", "database": ["astronomy"], "keywords": [], "year": "2015", "doctype": "article", "citation_count": 3954, "domain_category": "planetary_science"}
{"bibcode": "2008Sci...320.1444B", "title": "Forests and Climate Change: Forcings, Feedbacks, and the Climate Benefits of Forests", "abstract": "The world’s forests influence climate through physical, chemical, and biological processes that affect planetary energetics, the hydrologic cycle, and atmospheric composition. These complex and nonlinear forest-atmosphere interactions can dampen or amplify anthropogenic climate change. Tropical, temperate, and boreal reforestation and afforestation attenuate global warming through carbon sequestration. Biogeophysical feedbacks can enhance or diminish this negative climate forcing. Tropical forests mitigate warming through evaporative cooling, but the low albedo of boreal forests is a positive climate forcing. The evaporative effect of temperate forests is unclear. The net climate forcing from these and other processes is not known. Forests are under tremendous pressure from global change. Interdisciplinary science that integrates knowledge of the many interacting climate services of forests with the impacts of global change is necessary to identify and understand as yet unexplored feedbacks in the Earth system and the potential of forests to mitigate climate change.", "database": ["astronomy", "general"], "keywords": [], "year": "2008", "doctype": "article", "citation_count": 3899, "domain_category": "planetary_science"}
{"bibcode": "2010Sci...327..977B", "title": "Kepler Planet-Detection Mission: Introduction and First Results", "abstract": "The Kepler mission was designed to determine the frequency of Earth-sized planets in and near the habitable zone of Sun-like stars. The habitable zone is the region where planetary temperatures are suitable for water to exist on a planet’s surface. During the first 6 weeks of observations, Kepler monitored 156,000 stars, and five new exoplanets with sizes between 0.37 and 1.6 Jupiter radii and orbital periods from 3.2 to 4.9 days were discovered. The density of the Neptune-sized Kepler-4b is similar to that of Neptune and GJ 436b, even though the irradiation level is 800,000 times higher. Kepler-7b is one of the lowest-density planets (~0.17 gram per cubic centimeter) yet detected. Kepler-5b, -6b, and -8b confirm the existence of planets with densities lower than those predicted for gas giant planets.", "database": ["astronomy", "general"], "keywords": ["ASTRONOMY"], "year": "2010", "doctype": "article", "citation_count": 3666, "domain_category": "planetary_science"}
{"bibcode": "1995Natur.378..355M", "title": "A Jupiter-mass companion to a solar-type star", "abstract": "The presence of a Jupiter-mass companion to the star 51 Pegasi is inferred from observations of periodic variations in the star's radial velocity. The companion lies only about eight million kilometres from the star, which would be well inside the orbit of Mercury in our Solar System. This object might be a gas-giant planet that has migrated to this location through orbital evolution, or from the radiative stripping of a brown dwarf.", "database": ["astronomy", "general"], "keywords": [], "year": "1995", "doctype": "article", "citation_count": 3412, "domain_category": "planetary_science"}
{"bibcode": "2002Sci...295.2418W", "title": "Self-Assembly at All Scales", "abstract": "Self-assembly is the autonomous organization of components into patterns or structures without human intervention. Self-assembling processes are common throughout nature and technology. They involve components from the molecular (crystals) to the planetary (weather systems) scale and many different kinds of interactions. The concept of self-assembly is used increasingly in many disciplines, with a different flavor and emphasis in each.", "database": ["astronomy", "physics", "general"], "keywords": ["CHEMISTRY"], "year": "2002", "doctype": "article", "citation_count": 3377, "domain_category": "planetary_science"}
{"bibcode": "2013Sci...340..448A", "title": "A Massive Pulsar in a Compact Relativistic Binary", "abstract": "Many physically motivated extensions to general relativity (GR) predict substantial deviations in the properties of spacetime surrounding massive neutron stars. We report the measurement of a 2.01 ± 0.04 solar mass (M<SUB>⊙</SUB>) pulsar in a 2.46-hour orbit with a 0.172 ± 0.003 M<SUB>⊙</SUB> white dwarf. The high pulsar mass and the compact orbit make this system a sensitive laboratory of a previously untested strong-field gravity regime. Thus far, the observed orbital decay agrees with GR, supporting its validity even for the extreme conditions present in the system. The resulting constraints on deviations support the use of GR-based templates for ground-based gravitational wave detectors. Additionally, the system strengthens recent constraints on the properties of dense matter and provides insight to binary stellar astrophysics and pulsar recycling.", "database": ["astronomy", "physics", "general"], "keywords": ["Pulsars", "Neutron Stars", "General relativity", "Tests of General relativity", "Gravitational Radiation", "Stellar evolution", "ASTRONOMY, ONLINE Astronomy, Applied-Physics, Planetary-Science", "Astrophysics - High Energy Astrophysical Phenomena", "Astrophysics - Solar and Stellar Astrophysics", "Condensed Matter - Quantum Gases", "General Relativity and Quantum Cosmology"], "year": "2013", "doctype": "article", "citation_count": 3376, "domain_category": "planetary_science"}
{"bibcode": "2013ApJS..208....4P", "title": "Modules for Experiments in Stellar Astrophysics (MESA): Planets, Oscillations, Rotation, and Massive Stars", "abstract": "We substantially update the capabilities of the open source software package Modules for Experiments in Stellar Astrophysics (MESA), and its one-dimensional stellar evolution module, MESA star. Improvements in MESA star's ability to model the evolution of giant planets now extends its applicability down to masses as low as one-tenth that of Jupiter. The dramatic improvement in asteroseismology enabled by the space-based Kepler and CoRoT missions motivates our full coupling of the ADIPLS adiabatic pulsation code with MESA star. This also motivates a numerical recasting of the Ledoux criterion that is more easily implemented when many nuclei are present at non-negligible abundances. This impacts the way in which MESA star calculates semi-convective and thermohaline mixing. We exhibit the evolution of 3-8 M <SUB>⊙</SUB> stars through the end of core He burning, the onset of He thermal pulses, and arrival on the white dwarf cooling sequence. We implement diffusion of angular momentum and chemical abundances that enable calculations of rotating-star models, which we compare thoroughly with earlier work. We introduce a new treatment of radiation-dominated envelopes that allows the uninterrupted evolution of massive stars to core collapse. This enables the generation of new sets of supernovae, long gamma-ray burst, and pair-instability progenitor models. We substantially modify the way in which MESA star solves the fully coupled stellar structure and composition equations, and we show how this has improved the scaling of MESA's calculational speed on multi-core processors. Updates to the modules for equation of state, opacity, nuclear reaction rates, and atmospheric boundary conditions are also provided. We describe the MESA Software Development Kit that packages all the required components needed to form a unified, maintained, and well-validated build environment for MESA. We also highlight a few tools developed by the community for rapid visualization of MESA star results.", "database": ["astronomy"], "keywords": ["asteroseismology", "methods: numerical", "planets and satellites: physical evolution", "stars: evolution", "stars: massive", "stars: rotation", "Astrophysics - Solar and Stellar Astrophysics", "Astrophysics - Instrumentation and Methods for Astrophysics"], "year": "2013", "doctype": "article", "citation_count": 3329, "domain_category": "planetary_science"}
{"bibcode": "1995RvGeo..33..241T", "title": "The geochemical evolution of the continental crust", "abstract": "A survey is given of the dimensions and composition of the present continental crust. The abundances of immobile elements in sedimentary rocks are used to establish upper crustal composition. The present upper crustal composition is attributed largely to intracrustal differentiation resulting in the production of granites senso lato. Underplating of the crust by ponded basaltic magmas is probably a major source of heat for intracrustal differentiation. The contrast between the present upper crustal composition and that of the Archean upper crust is emphasized. The nature of the lower crust is examined in the light of evidence from granulities and xenoliths of lower crustal origin. It appears thathe protoliths of most granulite facies exposures are more representative of upper or middle crust and that the lower crust has a much more basic composition that the exposed upper crust. There is growing consensus that the crust grows episodically, and it is concluded that at least 60% of the crust was emplaced by the late Archean (ca. 2.7 eons, or 2.7 Ga). There appears to be a relationship between episodes of continental growth and differentiation and supercontinental cycles, probably dating back at least to the late Archean. <P />However, such cycles do not explain the constrast in crustal compositions between Archean and post-Archean. Mechanisms for deriving the crust from the mantle are considered, including the role of present-day plate tectonics and subduction zones. It is concluded that a somewhat different tectonic regime operated in the Archean and was responsible for the growth of much of the continental crust. Archean tonalites and trondhjemites may have resulted from slab melting and/or from melting of the Archean mantle wedge but at low pressures and high temperatures analogous to modern boninites. In contrast, most andesites and subduction-related rocks, now the main contributors to crustal growth, are derived ultimately from the mantle wedge above subduction zones. The cause of the contrast between the procesess responsible for Archean and post-Archean crustal growth is attributed to faster subduction of younger, hotter oceanic crust in the Archean (ultimately due to higher heat flow) compared with subduction of older, cooler oceanic crust in more recent times. A brief survey of the causes of continental breakup reveals that neither plume nor lithospheric stretching is a totally satisfactory explanation. Speculations are presented about crustal development before 4000 m.y. ago. The terrestrial continental crust appears to be unique compared with crust on other planets and satellites in the solar system, ultimately a consequence of the abundant free water on the Earth.", "database": ["astronomy", "physics", "earth science"], "keywords": ["Geochemistry: Chemical evolution", "Geochemistry: Composition of the crust", "Geochemistry: Planetary geochemistry"], "year": "1995", "doctype": "article", "citation_count": 3310, "domain_category": "planetary_science"}
{"bibcode": "2001ApJ...553...47F", "title": "Final Results from the Hubble Space Telescope Key Project to Measure the Hubble Constant", "abstract": "We present here the final results of the Hubble Space Telescope (HST) Key Project to measure the Hubble constant. We summarize our method, the results, and the uncertainties, tabulate our revised distances, and give the implications of these results for cosmology. Our results are based on a Cepheid calibration of several secondary distance methods applied over the range of about 60-400 Mpc. The analysis presented here benefits from a number of recent improvements and refinements, including (1) a larger LMC Cepheid sample to define the fiducial period-luminosity (PL) relations, (2) a more recent HST Wide Field and Planetary Camera 2 (WFPC2) photometric calibration, (3) a correction for Cepheid metallicity, and (4) a correction for incompleteness bias in the observed Cepheid PL samples. We adopt a distance modulus to the LMC (relative to which the more distant galaxies are measured) of μ<SUB>0</SUB>(LMC)=18.50+/-0.10 mag, or 50 kpc. New, revised distances are given for the 18 spiral galaxies for which Cepheids have been discovered as part of the Key Project, as well as for 13 additional galaxies with published Cepheid data. The new calibration results in a Cepheid distance to NGC 4258 in better agreement with the maser distance to this galaxy. Based on these revised Cepheid distances, we find values (in km s<SUP>-1</SUP> Mpc<SUP>-1</SUP>) of H<SUB>0</SUB>=71+/-2 (random)+/-6 (systematic) (Type Ia supernovae), H<SUB>0</SUB>=71+/-3+/-7 (Tully-Fisher relation), H<SUB>0</SUB>=70+/-5+/-6 (surface brightness fluctuations), H<SUB>0</SUB>=72+/-9+/-7 (Type II supernovae), and H<SUB>0</SUB>=82+/-6+/-9 (fundamental plane). We combine these results for the different methods with three different weighting schemes, and find good agreement and consistency with H<SUB>0</SUB>=72+/-8 km s<SUP>-1</SUP> Mpc<SUP>-1</SUP>. Finally, we compare these results with other, global methods for measuring H<SUB>0</SUB>. Based on observations with the NASA/ESA Hubble Space Telescope, obtained at the Space Telescope Science Institute, which is operated by AURA, Inc., under NASA contract NAS5-26555.", "database": ["astronomy"], "keywords": ["Stars: Variables: Cepheids", "Cosmology: Observations", "Cosmology: Distance Scale", "Galaxies: Distances and Redshifts", "Astrophysics"], "year": "2001", "doctype": "article", "citation_count": 3207, "domain_category": "planetary_science"}
{"bibcode": "2004A&A...428..261L", "title": "A long-term numerical solution for the insolation quantities of the Earth", "abstract": "We present here a new solution for the astronomical computation of the insolation quantities on Earth spanning from -250 Myr to 250 Myr. This solution has been improved with respect to La93 (Laskar et al. \\cite{Laskar1993}) by using a direct integration of the gravitational equations for the orbital motion, and by improving the dissipative contributions, in particular in the evolution of the Earth-Moon System. The orbital solution has been used for the calibration of the Neogene period (Lourens et al. \\cite{Lourens2004}), and is expected to be used for age calibrations of paleoclimatic data over 40 to 50 Myr, eventually over the full Palaeogene period (65 Myr) with caution. Beyond this time span, the chaotic evolution of the orbits prevents a precise determination of the Earth's motion. However, the most regular components of the orbital solution could still be used over a much longer time span, which is why we provide here the solution over 250 Myr. Over this time interval, the most striking feature of the obliquity solution, apart from a secular global increase due to tidal dissipation, is a strong decrease of about 0.38 degree in the next few millions of years, due to the crossing of the s<SUB>6</SUB>+g<SUB>5</SUB>-g<SUB>6</SUB> resonance (Laskar et al. \\cite{Laskar1993}). For the calibration of the Mesozoic time scale (about 65 to 250 Myr), we propose to use the term of largest amplitude in the eccentricity, related to g<SUB>2</SUB>-g<SUB>5</SUB>, with a fixed frequency of 3.200''/yr, corresponding to a period of 405 000 yr. The uncertainty of this time scale over 100 Myr should be about 0.1%, and 0.2% over the full Mesozoic era.", "database": ["astronomy"], "keywords": ["chaos", "celestial mechanics", "ephemerides", "Earth"], "year": "2004", "doctype": "article", "citation_count": 3204, "domain_category": "planetary_science"}
{"bibcode": "1992ARA&A..30..543M", "title": "Smoothed particle hydrodynamics.", "abstract": "The fundamentals of the smoothed particle hydrodynamics (SPH) method and its applications in astrophysics are reviewed. The discussion covers equations of motion, viscosity amd thermal conduction, spatially varying resolution, kernels, magnetic fields, special relativity, and implementation. Applications of the SPH method are discussed with reference to gas dynamics, binary stars and stellar collisions, formation of the moon and impact problems, fragmentation and cloud collisions, and cosmological and galactic problems. Other applications discussed include disks and rings, radio jets, motion near black holes, supernovae, magnetic phenomena, and nearly incompressible flow.", "database": ["astronomy"], "keywords": ["Computational Fluid Dynamics", "Finite Difference Theory", "Hydrodynamics", "Kernel Functions", "Particle Energy", "Particle Mass", "Angular Momentum", "Partial Differential Equations", "Particle In Cell Technique", "Pressure Gradients", "Astrophysics"], "year": "1992", "doctype": "article", "citation_count": 2990, "domain_category": "planetary_science"}
{"bibcode": "2003ARA&A..41...57L", "title": "Embedded Clusters in Molecular Clouds", "abstract": "Stellar clusters are born embedded within giant molecular clouds (GMCs) and during their formation and early evolution are often only visible at infrared wavelengths, being heavily obscured by dust. Over the past 15 years advances in infrared detection capabilities have enabled the first systematic studies of embedded clusters in galactic molecular clouds. In this article we review the current state of empirical knowledge concerning these extremely young protocluster systems. From a survey of the literature we compile the first extensive catalog of galactic embedded clusters. We use the catalog to construct the mass function and estimate the birthrate for embedded clusters within 2 kpc of the sun. We find that the embedded cluster birthrate exceeds that of visible open clusters by an order of magnitude or more indicating a high infant mortality rate for protocluster systems. Less than 4-7% of embedded clusters survive emergence from molecular clouds to become bound clusters of Pleiades age. The vast majority (90%) of stars that form in embedded clusters form in rich clusters of 100 or more members with masses in excess of 50 M<SUB>⊙</SUB>. Moreover, observations of nearby cloud complexes indicate that embedded clusters account for a significant (70-90%) fraction of all stars formed in GMCs. We review the role of embedded clusters in investigating the nature of the initial mass function (IMF) that, in one nearby example, has been measured over the entire range of stellar and substellar mass, from OB stars to substellar objects near the deuterium burning limit. We also review the role embedded clusters play in the investigation of circumstellar disk evolution and the important constraints they provide for understanding the origin of planetary systems. Finally, we discuss current ideas concerning the origin and dynamical evolution of embedded clusters and the implications for the formation of bound open clusters.", "database": ["astronomy"], "keywords": ["Astrophysics"], "year": "2003", "doctype": "article", "citation_count": 2897, "domain_category": "planetary_science"}
{"bibcode": "1996Icar..124...62P", "title": "Formation of the Giant Planets by Concurrent Accretion of Solids and Gas", "abstract": "New numerical simulations of the formation of the giant planets are presented, in which for the first time both the gas and planetesimal accretion rates are calculated in a self-consistent, interactive fashion. The simulations combine three elements: (1) three-body accretion cross sections of solids onto an isolated planetary embryo, (2) a stellar evolution code for the planet's gaseous envelope, and (3) a planetesimal dissolution code within the envelope, used to evaluate the planet's effective capture radius and the energy deposition profile of accreted material. Major assumptions include: The planet is embedded in a disk of gas and small planetesimals with locally uniform initial surface mass density, and planetesimals are not allowed to migrate into or out of the planet's feeding zone. <P />All simulations are characterized by three major phases. During the first phase, the planet's mass consists primarily of solid material. The planetesimal accretion rate, which dominates that of gas, rapidly increases owing to runaway accretion, then decreases as the planet's feeding zone is depleted. During the second phase, both solid and gas accretion rates are small and nearly independent of time. The third phase, marked by runaway gas accretion, starts when the solid and gas masses are about equal. It is engendered by a strong positive feedback on the gas accretion rates, driven by the rapid contraction of the gaseous envelope and the rapid expansion of the outer boundary, which depends on the planet's total mass. The overall evolutionary time scale is generally determined by the length of the second phase. <P />The actual rates at which the giant planets accreted small planetesimals is probably intermediate between the constant rates assumed in most previous studies and the highly variable rates used here. Within the context of the adopted model of planetesimal accretion, the joint constraints of the time scale for dissipation of the solar nebula and the current high-Zmasses of the giant planets lead to estimates of the initial surface density (σ<SUB>init</SUB>) of planetesimals in the outer region of the solar nebula. The results show that σ<SUB>init</SUB>≈ 10 g cm<SUP>-2</SUP>near Jupiter's orbit and that σ<SUB>init</SUB>∝a<SUP>-2</SUP>, whereais the distance from the Sun. These values are a factor of 3 to 4 times as high as that of the \"minimum-mass\" solar nebula at Jupiter's distance and a factor of 2 to 3 times as high at Saturn's distance. The estimates for the formation time of Jupiter and Saturn are 1 to 10 million years, whereas those for Uranus fall in the range 2 to 16 million years. These estimates follow from the properties of our Solar System and do not necessarily apply to giant planets in other planetary systems.", "database": ["astronomy", "earth science"], "keywords": [], "year": "1996", "doctype": "article", "citation_count": 2716, "domain_category": "planetary_science"}
{"bibcode": "1974MNRAS.168..603L", "title": "The evolution of viscous discs and the origin of the nebular variables.", "abstract": "The evolution of discs under the action of viscosity is studied by both similarity solutions and Green's functions. The angular momentum is steadily concentrated onto a small fraction of the mass which orbits at greater and greater radii while the rest is accreted onto the central body. We assume that the angular momentum excess of a proto-star is initially concentrated onto one-third of the total mass which forms a disc orbiting the new-born star. Viscous dissipation in this disc will cause it to shine with a luminosity greater than the final main sequence star for a period of io yr or so. Most of the properties of T Tauri stars can be explained as a consequence of disc evolution. Flares in Flare stars are interpreted as the entry of blobs of an old disc into the late type stellar atmospheres. On this hypothesis flaring activity could be observed in M stars of up to 5 x io yr old, and planetary systems will be common. Disc solutions appropriate to dwarf novae and X-ray sources are also given.", "database": ["astronomy"], "keywords": [], "year": "1974", "doctype": "article", "citation_count": 2688, "domain_category": "planetary_science"}
{"bibcode": "2014LRR....17....4W", "title": "The Confrontation between General Relativity and Experiment", "abstract": "The status of experimental tests of general relativity and of theoretical frameworks for analyzing them is reviewed and updated. Einstein's equivalence principle (EEP) is well supported by experiments such as the Eötvös experiment, tests of local Lorentz invariance and clock experiments. Ongoing tests of EEP and of the inverse square law are searching for new interactions arising from unification or quantum gravity. Tests of general relativity at the post-Newtonian level have reached high precision, including the light deflection, the Shapiro time delay, the perihelion advance of Mercury, the Nordtvedt effect in lunar motion, and frame-dragging. Gravitational wave damping has been detected in an amount that agrees with general relativity to better than half a percent using the Hulse-Taylor binary pulsar, and a growing family of other binary pulsar systems is yielding new tests, especially of strong-field effects. Current and future tests of relativity will center on strong gravity and gravitational waves.", "database": ["astronomy", "physics"], "keywords": ["Tests of relativistic gravity", "Theories of gravity", "Post-Newtonian limit", "Gravitational radiation", "General Relativity and Quantum Cosmology", "Astrophysics - Cosmology and Nongalactic Astrophysics", "High Energy Physics - Theory"], "year": "2014", "doctype": "article", "citation_count": 2673, "domain_category": "planetary_science"}
{"bibcode": "1987ARA&A..25...23S", "title": "Star formation in molecular clouds: observation and theory.", "abstract": "Star-formation (SF) processes occurring on the scale of giant molecular clouds (10 to the 6th solar masses and 10 to the 20th cm) or smaller are discussed, reviewing the results of recent theoretical and observational investigations. Topics examined include the origin of stellar masses; bimodal SF; initial mass functions; binary stars, bound clusters, and hierarchical fragmentation; and the efficiency of SF. The properties of molecular clouds and the origin of substructures in molecular clumps are explored in detail, and consideration is given to gravitational collapse and protostars, bipolar outflows from young stellar objects, visible young stellar objects, and the implications for binary-star and planetary-system formation.", "database": ["astronomy"], "keywords": ["Astrophysics", "Molecular Clouds", "Star Formation", "Stellar Models", "Astronomical Maps", "Binary Stars", "Gravitational Collapse", "Protostars", "Star Clusters", "Stellar Mass", "Astrophysics", "Molecular Clouds:Star Formation", "Pre-Main-Sequence Stars:Star Formation", "Protostars:Stellar Evolution", "Star Formation:Molecular Clouds", "Star Formation:Pre-Main-Sequence Stars", "Stellar Evolution:Protostars"], "year": "1987", "doctype": "article", "citation_count": 2658, "domain_category": "planetary_science"}
{"bibcode": "1992Sci...255..423C", "title": "Climate Forcing by Anthropogenic Aerosols", "abstract": "Although long considered to be of marginal importance to global climate change, tropospheric aerosol contributes substantially to radiative forcing, and anthropogenic sulfate aerosol in particular has imposed a major perturbation to this forcing. Both the direct scattering of short-wavelength solar radiation and the modification of the shortwave reflective properties of clouds by sulfate aerosol particles increase planetary albedo, thereby exerting a cooling influence on the planet. Current climate forcing due to anthropogenic sulfate is estimated to be -1 to -2 watts per square meter, globally averaged. This perturbation is comparable in magnitude to current anthropogenic greenhouse gas forcing but opposite in sign. Thus, the aerosol forcing has likely offset global greenhouse warming to a substantial degree. However, differences in geographical and seasonal distributions of these forcings preclude any simple compensation. Aerosol effects must be taken into account in evaluating anthropogenic influences on past, current, and projected future climate and in formulating policy regarding controls on emission of greenhouse gases and sulfur dioxide. Resolution of such policy issues requires integrated research on the magnitude and geographical distribution of aerosol climate forcing and on the controlling chemical and physical processes.", "database": ["astronomy", "physics", "general"], "keywords": [], "year": "1992", "doctype": "article", "citation_count": 2620, "domain_category": "planetary_science"}
{"bibcode": "2001ApJ...556..121K", "title": "Theoretical Modeling of Starburst Galaxies", "abstract": "We have modeled a large sample of infrared starburst galaxies using both the PEGASE v2.0 and STARBURST99 codes to generate the spectral energy distribution (SED) of the young star clusters. PEGASE utilizes the Padova group tracks, while STARBURST99 uses the Geneva group tracks, allowing comparison between the two. We used our MAPPINGS III code to compute photoionization models that include a self-consistent treatment of dust physics and chemical depletion. We use the standard optical diagnostic diagrams as indicators of the hardness of the EUV radiation field in these galaxies. These diagnostic diagrams are most sensitive to the spectral index of the ionizing radiation field in the 1-4 ryd region. We find that warm infrared starburst galaxies contain a relatively hard EUV field in this region. The PEGASE ionizing stellar continuum is harder in the 1-4 ryd range than that of STARBURST99. As the spectrum in this regime is dominated by emission from Wolf-Rayet (W-R) stars, this discrepancy is most likely due to the differences in stellar atmosphere models used for the W-R stars. The PEGASE models use the Clegg &amp; Middlemass planetary nebula nuclei (PNN) atmosphere models for the W-R stars, whereas the STARBURST99 models use the Schmutz, Leitherer, &amp; Gruenwald W-R atmosphere models. We believe that the Schmutz et al. atmospheres are more applicable to the starburst galaxies in our sample; however, they do not produce the hard EUV field in the 1-4 ryd region required by our observations. The inclusion of continuum metal blanketing in the models may be one solution. Supernova remnant (SNR) shock modeling shows that the contribution by mechanical energy from SNRs to the photoionization models is &lt;&lt;20%. The models presented here are used to derive a new theoretical classification scheme for starbursts and active galactic nucleus (AGN) galaxies based on the optical diagnostic diagrams.", "database": ["astronomy"], "keywords": ["Galaxies: Starburst", "Radiation Mechanisms: Thermal", "Astrophysics"], "year": "2001", "doctype": "article", "citation_count": 2585, "domain_category": "planetary_science"}
{"bibcode": "2008E&PSL.273...48B", "title": "The Lu-Hf and Sm-Nd isotopic composition of CHUR: Constraints from unequilibrated chondrites and implications for the bulk composition of terrestrial planets", "abstract": "The Lutetium-Hafnium radiogenic isotopic system is widely used as a chronometer and tracer of planetary evolution. In order for this isotopic system to fulfill its potential in planetary studies, the Lu-Hf system parameters need to be more tightly constrained, in particular the Lu-Hf isotopic composition of the chondritic uniform reservoir (CHUR) and, by extension, the bulk silicate Earth (BSE). We present new Lu-Hf and Sm-Nd isotopic compositions of unequilibrated carbonaceous, ordinary, and enstatite chondrites of petrologic types 1, 2, and 3 which define a narrow range of Lu/Hf ratios (3%) identical with that of Sm/Nd. This contrasts with previously published data from mostly equilibrated ordinary chondrites of petrologic types 4, 5, and 6 which have a much larger range in Lu/Hf (28%). This heterogeneity has hampered an unambiguous choice for the Lu-Hf isotopic composition of CHUR. Our new determinations of Lu-Hf CHUR parameters are <SUP>176</SUP>Lu/<SUP>177</SUP>Hf = 0.0336 ± 1 and <SUP>176</SUP>Hf/<SUP>177</SUP>Hf = 0.282785 ± 11 (2σ<SUB>m</SUB>), which are higher than previous estimates and, together with average Sm-Nd chondrite compositions of unequilibrated chondrites of <SUP>147</SUP>Sm/<SUP>144</SUP>Nd = 0.1960 ± 4 and <SUP>143</SUP>Nd/<SUP>144</SUP>Nd = 0.512630 ± 11 (2σ<SUB>m</SUB>), now provide firm constraints on the chondritic parameters for both Lu-Hf and Sm-Nd isotopic systems. A comparison of Lu-Hf and Sm-Nd data show that terrestrial planets, as well as early differentiated planetesimals, converge toward a common initial Hf and Nd isotope composition corresponding to the average of chondrites. Finally, a compilation of Lu-Hf isotopic data of unequilibrated and equilibrated chondrites demonstrates that the <SUP>176</SUP>Lu decay decay-constant value cannot be resolved by age comparison on metamorphosed or shocked planetary materials which have a complex history.", "database": ["astronomy", "earth science"], "keywords": [], "year": "2008", "doctype": "article", "citation_count": 2510, "domain_category": "planetary_science"}
{"bibcode": "1965PhRv..140.1133K", "title": "Self-Consistent Equations Including Exchange and Correlation Effects", "abstract": "From a theory of Hohenberg and Kohn, approximation methods for treating an inhomogeneous system of interacting electrons are developed. These methods are exact for systems of slowly varying or high density. For the ground state, they lead to self-consistent equations analogous to the Hartree and Hartree-Fock equations, respectively. In these equations the exchange and correlation portions of the chemical potential of a uniform electron gas appear as additional effective potentials. (The exchange portion of our effective potential differs from that due to Slater by a factor of 23.) Electronic systems at finite temperatures and in magnetic fields are also treated by similar methods. An appendix deals with a further correction for systems with short-wavelength density oscillations.", "database": ["physics"], "keywords": [], "year": "1965", "doctype": "article", "citation_count": 39706, "domain_category": "multidisciplinary"}
{"bibcode": "2009RvMP...81..109C", "title": "The electronic properties of graphene", "abstract": "This article reviews the basic theoretical aspects of graphene, a one-atom-thick allotrope of carbon, with unusual two-dimensional Dirac-like electronic excitations. The Dirac electrons can be controlled by application of external electric and magnetic fields, or by altering sample geometry and/or topology. The Dirac electrons behave in unusual ways in tunneling, confinement, and the integer quantum Hall effect. The electronic properties of graphene stacks are discussed and vary with stacking order and number of layers. Edge (surface) states in graphene depend on the edge termination (zigzag or armchair) and affect the physical properties of nanoribbons. Different types of disorder modify the Dirac equation leading to unusual spectroscopic and transport properties. The effects of electron-electron and electron-phonon interactions in single layer and multilayer graphene are also presented.", "database": ["physics"], "keywords": ["81.05.Uw", "73.20.-r", "03.65.Pm", "82.45.Mp", "Carbon diamond graphite", "Electron states at surfaces and interfaces", "Relativistic wave equations", "Thin layers films monolayers membranes", "Condensed Matter - Other"], "year": "2009", "doctype": "article", "citation_count": 17712, "domain_category": "multidisciplinary"}
{"bibcode": "1972Natur.238...37F", "title": "Electrochemical Photolysis of Water at a Semiconductor Electrode", "abstract": "ALTHOUGH the possibility of water photolysis has been investigated by many workers, a useful method has only now been developed. Because water is transparent to visible light it cannot be decomposed directly, but only by radiation with wavelengths shorter than 190 nm (ref. 1).", "database": ["physics", "general"], "keywords": [], "year": "1972", "doctype": "article", "citation_count": 15152, "domain_category": "multidisciplinary"}
{"bibcode": "2020Natur.585..357H", "title": "Array programming with NumPy", "abstract": "Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves<SUP>1</SUP> and in the first imaging of a black hole<SUP>2</SUP>. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.", "database": ["general"], "keywords": ["Computer Science - Mathematical Software", "Statistics - Computation"], "year": "2020", "doctype": "article", "citation_count": 13690, "domain_category": "multidisciplinary"}
{"bibcode": "1998Natur.393..440W", "title": "Collective dynamics of `small-world' networks", "abstract": "Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays,, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks `rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them `small-world' networks, by analogy with the small-world phenomenon, (popularly known as six degrees of separation). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.", "database": ["physics", "general"], "keywords": [], "year": "1998", "doctype": "article", "citation_count": 12598, "domain_category": "multidisciplinary"}
{"bibcode": "1989ApJ...345..245C", "title": "The Relationship between Infrared, Optical, and Ultraviolet Extinction", "abstract": "The parameterized extinction data of Fitzpatrick and Massa (1986, 1988) for the ultraviolet and various sources for the optical and near-infrared are used to derive a meaningful average extinction law over the 3.5 micron to 0.125 wavelength range which is applicable to both diffuse and dense regions of the interstellar medium. The law depends on only one parameter R(V) = A(V)/E(B-V). An analytic formula is given for the mean extinction law which can be used to calculate color excesses or to deredden observations. The validity of the law over a large wavelength interval suggests that the processes which modify the sizes and compositions of grains are stochastic in nature and very efficient.", "database": ["astronomy"], "keywords": ["Infrared Spectra", "Interstellar Extinction", "Ultraviolet Spectra", "Visible Spectrum", "Computational Astrophysics", "Interstellar Matter", "Iue", "Astrophysics", "INTERSTELLAR: MATTER", "ULTRAVIOLET: SPECTRA"], "year": "1989", "doctype": "article", "citation_count": 11259, "domain_category": "multidisciplinary"}
{"bibcode": "2010PhRvL.105m6805M", "title": "Atomically Thin MoS<SUB>2</SUB>: A New Direct-Gap Semiconductor", "abstract": "The electronic properties of ultrathin crystals of molybdenum disulfide consisting of N=1,2,…,6 S-Mo-S monolayers have been investigated by optical spectroscopy. Through characterization by absorption, photoluminescence, and photoconductivity spectroscopy, we trace the effect of quantum confinement on the material’s electronic structure. With decreasing thickness, the indirect band gap, which lies below the direct gap in the bulk material, shifts upwards in energy by more than 0.6 eV. This leads to a crossover to a direct-gap material in the limit of the single monolayer. Unlike the bulk material, the MoS<SUB>2</SUB> monolayer emits light strongly. The freestanding monolayer exhibits an increase in luminescence quantum efficiency by more than a factor of 10<SUP>4</SUP> compared with the bulk material.", "database": ["physics"], "keywords": ["73.21.Ac", "71.20.Nr", "78.20.Ci", "78.30.Hv", "Multilayers", "Semiconductor compounds", "Optical constants", "Other nonmetallic inorganics", "Condensed Matter - Materials Science", "Condensed Matter - Mesoscale and Nanoscale Physics"], "year": "2010", "doctype": "article", "citation_count": 10059, "domain_category": "multidisciplinary"}
{"bibcode": "1999JChPh.110.6158A", "title": "Toward reliable density functional methods without adjustable parameters: The PBE0 model", "abstract": "We present an analysis of the performances of a parameter free density functional model (PBE0) obtained combining the so called PBE generalized gradient functional with a predefined amount of exact exchange. The results obtained for structural, thermodynamic, kinetic and spectroscopic (magnetic, infrared and electronic) properties are satisfactory and not far from those delivered by the most reliable functionals including heavy parameterization. The way in which the functional is derived and the lack of empirical parameters fitted to specific properties make the PBE0 model a widely applicable method for both quantum chemistry and condensed matter physics.", "database": ["physics"], "keywords": ["31.15.Ew", "71.15.Mb", "Density-functional theory", "Density functional theory local density approximation gradient and other corrections"], "year": "1999", "doctype": "article", "citation_count": 9653, "domain_category": "multidisciplinary"}
{"bibcode": "1964AnaCh..36.1627S", "title": "Smoothing and differentiation of data by simplified least squares procedures", "abstract": "In attempting to analyze, on digital computers, data from basically continuous physical experiments, numerical methods of performing familiar operations must be developed. The operations of differentiation and filtering are especially important both as an end in themselves, and as a prelude to further treatment of the data. Numerical counterparts of analog devices that perform these operations, such as RC filters, are often considered. However, the method of least squares may be used without additional computational complexity and with considerable improvement in the information obtained. The least squares calculations may be carried out in the computer by convolution of the data points with properly chosen sets of integers. These sets of integers and their normalizing factors are described and their use is illustrated in spectroscopic applications. The computer programs required are relatively simple. Two examples are presented as subroutines in the FORTRAN language.", "database": ["astronomy"], "keywords": [], "year": "1964", "doctype": "article", "citation_count": 9465, "domain_category": "multidisciplinary"}
{"bibcode": "1998PhRvB..57.1505D", "title": "Electron-energy-loss spectra and the structural stability of nickel oxide: An LSDA+U study", "abstract": "We demonstrate how by taking better account of electron correlations in the 3d shell of metal ions in nickel oxide it is possible to improve the description of both electron energy loss spectra and parameters characterizing the structural stability of the material compared with local spin density functional theory.", "database": ["physics"], "keywords": ["71.27.+a", "71.10.-w", "82.80.Pv", "Strongly correlated electron systems", "heavy fermions", "Theories and models of many-electron systems", "Electron spectroscopy"], "year": "1998", "doctype": "article", "citation_count": 9241, "domain_category": "multidisciplinary"}
{"bibcode": "2021Natur.596..583J", "title": "Highly accurate protein structure prediction with AlphaFold", "abstract": "Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort<SUP>1-4</SUP>, the structures of around 100,000 unique proteins have been determined<SUP>5</SUP>, but this represents a small fraction of the billions of known protein sequences<SUP>6,7</SUP>. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the `protein folding problem'<SUP>8</SUP>—has been an important open research problem for more than 50 years<SUP>9</SUP>. Despite recent progress<SUP>10-14</SUP>, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)<SUP>15</SUP>, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.", "database": ["general"], "keywords": [], "year": "2021", "doctype": "article", "citation_count": 8826, "domain_category": "multidisciplinary"}
{"bibcode": "2014Bioin..30.1312S", "title": "RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies", "abstract": "Motivation: Phylogenies are increasingly used in all fields of medical and biological research. Moreover, because of the next-generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace. RAxML (Randomized Axelerated Maximum Likelihood) is a popular program for phylogenetic analyses of large datasets under maximum likelihood. Since the last RAxML paper in 2006, it has been continuously maintained and extended to accommodate the increasingly growing input datasets and to serve the needs of the user community. Results: I present some of the most notable new features and extensions of RAxML, such as a substantial extension of substitution models and supported data types, the introduction of SSE3, AVX and AVX2 vector intrinsics, techniques for reducing the memory requirements of the code and a plethora of operations for conducting post-analyses on sets of trees. In addition, an up-to-date 50-page user manual covering all new RAxML options is available. Availability and implementation: The code is available under GNU GPL at https://github.com/stamatak/standard-RAxML. Contact: alexandros.stamatakis@h-its.org Supplementary information: Supplementary data are available at Bioinformatics online.", "database": ["general"], "keywords": [], "year": "2014", "doctype": "article", "citation_count": 7701, "domain_category": "multidisciplinary"}
{"bibcode": "2000PhRvL..85.3966P", "title": "Negative Refraction Makes a Perfect Lens", "abstract": "With a conventional lens sharpness of the image is always limited by the wavelength of light. An unconventional alternative to a lens, a slab of negative refractive index material, has the power to focus all Fourier components of a 2D image, even those that do not propagate in a radiative manner. Such ``superlenses'' can be realized in the microwave band with current technology. Our simulations show that a version of the lens operating at the frequency of visible light can be realized in the form of a thin slab of silver. This optical version resolves objects only a few nanometers across.", "database": ["physics"], "keywords": [], "year": "2000", "doctype": "article", "citation_count": 7495, "domain_category": "multidisciplinary"}
{"bibcode": "2010AJ....140.1868W", "title": "The Wide-field Infrared Survey Explorer (WISE): Mission Description and Initial On-orbit Performance", "abstract": "The all sky surveys done by the Palomar Observatory Schmidt, the European Southern Observatory Schmidt, and the United Kingdom Schmidt, the InfraRed Astronomical Satellite, and the Two Micron All Sky Survey have proven to be extremely useful tools for astronomy with value that lasts for decades. The Wide-field Infrared Survey Explorer (WISE) is mapping the whole sky following its launch on 2009 December 14. WISE began surveying the sky on 2010 January 14 and completed its first full coverage of the sky on July 17. The survey will continue to cover the sky a second time until the cryogen is exhausted (anticipated in 2010 November). WISE is achieving 5σ point source sensitivities better than 0.08, 0.11, 1, and 6 mJy in unconfused regions on the ecliptic in bands centered at wavelengths of 3.4, 4.6, 12, and 22 μm. Sensitivity improves toward the ecliptic poles due to denser coverage and lower zodiacal background. The angular resolution is 6farcs1, 6farcs4, 6farcs5, and 12farcs0 at 3.4, 4.6, 12, and 22 μm, and the astrometric precision for high signal-to-noise sources is better than 0farcs15.", "database": ["astronomy"], "keywords": ["infrared: general", "space vehicles", "surveys", "Astrophysics - Instrumentation and Methods for Astrophysics"], "year": "2010", "doctype": "article", "citation_count": 7446, "domain_category": "multidisciplinary"}
{"bibcode": "2003Natur.424..824B", "title": "Surface plasmon subwavelength optics", "abstract": "Surface plasmons are waves that propagate along the surface of a conductor. By altering the structure of a metal's surface, the properties of surface plasmons-in particular their interaction with light-can be tailored, which offers the potential for developing new types of photonic device. This could lead to miniaturized photonic circuits with length scales that are much smaller than those currently achieved. Surface plasmons are being explored for their potential in subwavelength optics, data storage, light generation, microscopy and bio-photonics.", "database": ["physics", "general"], "keywords": [], "year": "2003", "doctype": "article", "citation_count": 7282, "domain_category": "multidisciplinary"}
{"bibcode": "2005JSynR..12..537R", "title": "ATHENA, ARTEMIS, HEPHAESTUS: data analysis for X-ray absorption spectroscopy using IFEFFIT", "abstract": "A description of a package of graphical data-analysis tools for X-ray absorption spectroscopy is given.", "database": ["earth science"], "keywords": ["XAS", "data analysis", "FEFF", "IFEFFIT"], "year": "2005", "doctype": "article", "citation_count": 7269, "domain_category": "multidisciplinary"}
{"bibcode": "2005PNAS..10215545S", "title": "From the Cover: Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles", "abstract": "Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.", "database": ["general"], "keywords": ["GENETICS"], "year": "2005", "doctype": "article", "citation_count": 6973, "domain_category": "multidisciplinary"}
{"bibcode": "2001RvMP...73..515B", "title": "Phonons and related crystal properties from density-functional perturbation theory", "abstract": "This article reviews the current status of lattice-dynamical calculations in crystals, using density-functional perturbation theory, with emphasis on the plane-wave pseudopotential method. Several specialized topics are treated, including the implementation for metals, the calculation of the response to macroscopic electric fields and their relevance to long-wavelength vibrations in polar materials, the response to strain deformations, and higher-order responses. The success of this methodology is demonstrated with a number of applications existing in the literature.", "database": ["physics"], "keywords": ["63.20.-e", "01.30.Rr", "Phonons in crystal lattices", "Surveys and tutorial papers", "resource letters", "Condensed Matter - Materials Science"], "year": "2001", "doctype": "article", "citation_count": 6969, "domain_category": "multidisciplinary"}
{"bibcode": "2003Natur.421...37P", "title": "A globally coherent fingerprint of climate change impacts across natural systems", "abstract": "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a `systematic trend'. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial `sign-switching' responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates `very high confidence' (as laid down by the IPCC) that climate change is already affecting living systems.", "database": ["physics", "general"], "keywords": [], "year": "2003", "doctype": "article", "citation_count": 6300, "domain_category": "multidisciplinary"}
{"bibcode": "2003SIAMR..45..167N", "title": "The Structure and Function of Complex Networks", "abstract": "Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.", "database": ["physics"], "keywords": ["networks", "graph theory", "complex systems", "computer networks", "social networks", "random graphs", "percolation theory", "Condensed Matter - Statistical Mechanics", "Condensed Matter - Disordered Systems and Neural Networks"], "year": "2003", "doctype": "article", "citation_count": 6298, "domain_category": "multidisciplinary"}
{"bibcode": "1993AusEc..18..117C", "title": "Non-parametric multivariate analyses of changes in community structure", "abstract": "Abstract In the early 1980s, a strategy for graphical representation of multivariate (multi-species) abundance data was introduced into marine ecology by, among others, Field, et al. (1982). A decade on, it is instructive to: (i) identify which elements of this often-quoted strategy have proved most useful in practical assessment of community change resulting from pollution impact; and (ii) ask to what extent evolution of techniques in the intervening years has added self-consistency and comprehensiveness to the approach. The pivotal concept has proved to be that of a biologically-relevant definition of similarity of two samples, and its utilization mainly in simple rank form, for example 'sample A is more similar to sample B than it is to sample C'. Statistical assumptions about the data are thus minimized and the resulting non-parametric techniques will be of very general applicability. From such a starting point, a unified framework needs to encompass: (i) the display of community patterns through clustering and ordination of samples; (ii) identification of species principally responsible for determining sample groupings; (iii) statistical tests for differences in space and time (multivariate analogues of analysis of variance, based on rank similarities); and (iv) the linking of community differences to patterns in the physical and chemical environment (the latter also dictated by rank similarities between samples). Techniques are described that bring such a framework into place, and areas in which problems remain are identified. Accumulated practical experience with these methods is discussed, in particular applications to marine benthos, and it is concluded that they have much to offer practitioners of environmental impact studies on communities.", "database": ["earth science"], "keywords": [], "year": "1993", "doctype": "article", "citation_count": 6243, "domain_category": "multidisciplinary"}
{"bibcode": "2001Bioin..17..754H", "title": "MRBAYES: Bayesian inference of phylogenetic trees", "abstract": "Summary: The program MRBAYES performs Bayesian inference of phylogeny using a variant of Markov chain Monte Carlo. Availability: MRBAYES, including the source code, documentation, sample data files, and an executable, is available at http://brahms.biology.rochester.edu/software.html. Contact: johnh@brahms.biology.rochester.edu", "database": ["general"], "keywords": [], "year": "2001", "doctype": "article", "citation_count": 6190, "domain_category": "multidisciplinary"}
{"bibcode": "2012PhRvD..86a0001B", "title": "Review of Particle Physics", "abstract": "This biennial Review summarizes much of particle physics. Using data from previous editions, plus 2658 new measurements from 644 papers, we list, evaluate, and average measured properties of gauge bosons, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as Higgs bosons, heavy neutrinos, and supersymmetric particles. All the particle properties and search limits are listed in Summary Tables. We also give numerous tables, figures, formulae, and reviews of topics such as the Standard Model, particle detectors, probability, and statistics. Among the 112 reviews are many that are new or heavily revised including those on Heavy-Quark and Soft-Collinear Effective Theory, Neutrino Cross Section Measurements, Monte Carlo Event Generators, Lattice QCD, Heavy Quarkonium Spectroscopy, Top Quark, Dark Matter, V<SUB>cb</SUB> &amp; V<SUB>ub</SUB>, Quantum Chromodynamics, High-Energy Collider Parameters, Astrophysical Constants, Cosmological Parameters, and Dark Matter.A booklet is available containing the Summary Tables and abbreviated versions of some of the other sections of this full Review. All tables, listings, and reviews (and errata) are also available on the Particle Data Group website: http://pdg.lbl.gov/.The 2012 edition of Review of Particle Physics is published for the Particle Data Group as article 010001 in volume 86 of Physical Review D.This edition should be cited as: J. Beringer et al. (Particle Data Group), Phys. Rev. D 86, 010001 (2012).", "database": ["physics"], "keywords": ["14.20.-c", "14.40.-n", "14.60.-z", "14.80.-j", "Baryons", "Mesons", "Leptons", "Other particles"], "year": "2012", "doctype": "article", "citation_count": 6142, "domain_category": "multidisciplinary"}
{"bibcode": "2011Sci...334..333Y", "title": "Light Propagation with Phase Discontinuities: Generalized Laws of Reflection and Refraction", "abstract": "Conventional optical components rely on gradual phase shifts accumulated during light propagation to shape light beams. New degrees of freedom are attained by introducing abrupt phase changes over the scale of the wavelength. A two-dimensional array of optical resonators with spatially varying phase response and subwavelength separation can imprint such phase discontinuities on propagating light as it traverses the interface between two media. Anomalous reflection and refraction phenomena are observed in this regime in optically thin arrays of metallic antennas on silicon with a linear phase variation along the interface, which are in excellent agreement with generalized laws derived from Fermat’s principle. Phase discontinuities provide great flexibility in the design of light beams, as illustrated by the generation of optical vortices through use of planar designer metallic interfaces.", "database": ["physics", "general"], "keywords": ["APP PHYSICS"], "year": "2011", "doctype": "article", "citation_count": 6093, "domain_category": "multidisciplinary"}
{"bibcode": "2007JApCr..40..658M", "title": "Phaser crystallographic software", "abstract": "A description is given of Phaser-2.1: software for phasing macromolecular crystal structures by molecular replacement and single-wavelength anomalous dispersion phasing.", "database": ["earth science"], "keywords": ["computer programs", "molecular replacement", "SAD phasing", "likelihood", "structural genomics"], "year": "2007", "doctype": "article", "citation_count": 6078, "domain_category": "multidisciplinary"}
