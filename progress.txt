# Ralph Progress Log
Started: Thu Jan 22 17:48:07 EST 2026

## Codebase Patterns

### ADS Field Constraints
- `packages/finetune/src/finetune/domains/scix/field_constraints.py` contains all enum field validations
- DOCTYPES: 22 valid values (article, eprint, inproceedings, etc.)
- PROPERTIES: 21 valid values (refereed, openaccess, data, eprint, etc.)
- DATABASES: 4 valid values (astronomy, physics, general, earthscience)
- BIBGROUPS: 55 valid values (HST, JWST, ALMA, SETI, ESO, etc.)
- ESOURCES: 8 valid values (PUB_PDF, EPRINT_PDF, etc.)
- DATA_SOURCES: 24 valid values (MAST, NED, SIMBAD, etc.)

### Bibgroup Synonyms
- `data/model/bibgroup_synonyms.json` - Telescope/survey common name to bibgroup code mappings
- 53 bibgroup entries with synonyms (Hubble->HST, Webb->JWST, Sloan->SDSS, etc.)
- reverse_lookup section for easy NL->code conversion

### Data Model Files
- `data/model/ads_field_inventory.json` - Complete field inventory with 57 fields, 8 operators, 9 field groups
- Includes syntax support documentation (wildcards, proximity, ranges, etc.)

---

## 2026-01-22 - US-001: Complete field inventory from ADS Solr schema
- **Implemented**: Complete ADS field inventory documenting all searchable fields
- **Files created**:
  - `data/model/ads_field_inventory.json` - Comprehensive field inventory
- **Key details**:
  - 57 searchable fields documented
  - 9 field groups: content, author, enum, identifier, metric, date, publication, classification, special
  - 8 operators: citations, references, trending, similar, useful, reviews, topn, pos
  - All syntax support documented (wildcards, proximity, ranges, etc.)
  - Constrained vocabulary fields have valid_values arrays
- **Learnings**:
  - ADS has earthscience collection but it's not in current field_constraints.py DATABASES
  - bibgroup synonyms needed (Hubble->HST, Webb->JWST, etc.)
  - Operator trigger patterns need expansion for NL variations
---

## 2026-01-22 - US-002: Audit current training data coverage
- **Implemented**: Comprehensive training data coverage audit script
- **Files created**:
  - `scripts/audit_training_coverage.py` - Coverage audit script
  - `data/datasets/evaluations/coverage_audit.json` - Detailed audit report
- **Key findings from audit**:
  - 4002 total examples in gold_examples.json
  - Field coverage: 30/57 fields have examples (27 with zero examples)
  - Operator coverage: All 8 operators have 10+ examples
  - Enum coverage:
    - doctype: 9/22 values (40.9%) - 13 unused including bookreview, circular, mastersthesis
    - property: 5/21 values (23.8%) - 16 unused including eprint, catalog, inspire
    - database: 3/3 values (100%) - but earthscience missing from constraints
    - bibgroup: 5/53 values (9.4%) - 48 unused telescopes/surveys
    - esources: 0/8 values (0%) - completely unused
  - Fields with zero examples: ack, caption, grant, lang, orcid variants, etc.
- **Learnings for future iterations**:
  - Use regex `(\w+):(?:\"([^\"]+)\"|(\([^)]+\))|(\[[^\]]+\])|(\S+))` to extract field:value pairs from queries
  - gold_examples.json uses categories like 'first_author', 'author', 'filters', 'content', etc.
  - The inventory can have values not yet in field_constraints.py (e.g., earthscience)
  - Coverage audit should run after each batch of example generation to track progress
---

## 2026-01-22 - US-003: Add earthscience to DATABASES and update bibgroup synonyms
- **Implemented**: Database and bibgroup constraint updates
- **Files created/modified**:
  - `packages/finetune/src/finetune/domains/scix/field_constraints.py` - Added earthscience to DATABASES, SETI and ESO to BIBGROUPS
  - `data/model/bibgroup_synonyms.json` - Created with 53 telescope/survey mappings
  - `packages/finetune/tests/test_validate.py` - Added tests for earthscience, SETI, ESO
  - `tests/test_constraint_edge_cases.py` - Added earthscience test case
- **Key changes**:
  - DATABASES now has 4 values: astronomy, physics, general, earthscience
  - BIBGROUPS now has 55 values (added SETI, ESO)
  - bibgroup_synonyms.json has reverse_lookup for common names
- **Learnings for future iterations**:
  - Coverage audit identified unknown values like SETI and ESO that needed to be added
  - Bibgroup synonyms file enables future NL->code mapping in NER
  - Tests should cover all new enum values to prevent regressions
---

## 2026-01-22 - US-004: Expand operator trigger patterns for flexibility
- **Implemented**: 70+ new operator trigger patterns for natural language variations
- **Files modified**:
  - `packages/finetune/src/finetune/domains/scix/ner.py` - Expanded OPERATOR_PATTERNS and OPERATOR_REMOVAL_PATTERNS
  - `tests/test_ner.py` - Added 100+ unit tests for new patterns
  - `tests/regression/test_operator_conflation.py` - Updated test for new expected behavior
- **Key changes**:
  - citations(): papers that cite, work/research/studies/articles citing, show/list citations
  - references(): sources/works cited by, what does X cite, papers it/they cite, show/list references
  - trending(): hot topics/papers, what's trending, trending research/topics, popular now/recently
  - similar(): related to/papers, work similar to, studies/papers resembling, comparable papers/work
  - useful(): helpful papers/research/work, foundational work/papers, essential reading/papers, must-read, key papers, seminal/landmark papers
  - reviews(): survey papers/articles, overviews of, comprehensive reviews/survey, literature review, systematic review, tutorial on, introduction to
- **Technical improvements**:
  - Reordered OPERATOR_PATTERNS dict to check "references" before "citations" for proper pattern priority
  - Made "references in" pattern more specific (requires paper/bibliography/appendix context) to avoid false positives on generic text
- **Learnings for future iterations**:
  - Dict order matters for pattern matching - more specific patterns should come first
  - Overly broad patterns like "references in X" can match unintended text - require additional context words
  - The parametrized test approach (pytest.mark.parametrize) makes testing many patterns efficient
  - When adding new patterns, check existing negative test cases to ensure they still pass
---

## 2026-01-22 - US-005: Generate database/collection training examples
- **Implemented**: Training data generation for database/collection queries
- **Files created**:
  - `scripts/generate_collection_examples.py` - Generates database-filtered training examples
  - `data/datasets/generated/collection_examples.json` - 88 unique examples
- **Key details**:
  - 25 astronomy examples (with 15 topics like dark matter, black holes, galaxy formation)
  - 25 physics examples (with 14 topics like quantum mechanics, string theory)
  - 13 general examples (interdisciplinary science)
  - 25 earthscience examples (previously 0 coverage) - Mars geology, climate, space weather
  - Combined queries: database + topic, database + date, database + refereed + topic + author
  - NL variations: "astronomy papers", "astrophysics literature", "earth science research", etc.
- **Learnings for future iterations**:
  - NL trigger phrases must be complete sentences/phrases that work in all template positions
  - Avoid partial phrases like "in astronomy" that break when prefixed with "get me" or "I want"
  - Use deduplication on natural_language field since random generation can create duplicates
  - Template-based generation with separate topic/date/combined categories works well
---

## 2026-01-22 - US-006: Generate property training examples for underrepresented values
- **Implemented**: Training data generation for property-based queries
- **Files created**:
  - `scripts/generate_property_examples.py` - Generates property-filtered training examples
  - `data/datasets/generated/property_examples.json` - 140 unique examples
- **Key details**:
  - 17 properties covered (16 underrepresented + software for more coverage)
  - 7-15 examples per property (notrefereed: 15, nonarticle: 13, others: 7)
  - NL variations: "preprints" -> property:eprint, "arxiv papers" -> property:eprint
  - Negation patterns: "papers that are not refereed" -> property:notrefereed
  - Combined queries: property + topic, property + date, property + author
  - Prevented conflicting combinations (e.g., notrefereed with refereed filter)
- **Properties with examples**:
  - notrefereed, eprint, catalog, article, nonarticle, inproceedings
  - associated, toc, presentation, esource, inspire, library_catalog
  - ads_openaccess, author_openaccess, eprint_openaccess, pub_openaccess
  - ocr_abstract, software
- **Learnings for future iterations**:
  - Some properties semantically conflict (notrefereed + refereed) - filter templates by property
  - Negation forms provide natural language diversity ("not refereed", "exclude peer-reviewed")
  - Topic lists per property improve relevance (e.g., INSPIRE -> particle physics topics)
  - Use case-insensitive deduplication to catch subtle duplicates
---
