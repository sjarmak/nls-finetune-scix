# Ralph Progress Log - SciX Fine-tuning

## CURRENT STATUS: Phase 3 Complete ‚úÖ

### v2-4k-pairs Model: LIVE & WORKING

**Endpoint**: https://sjarmak--nls-finetune-serve-vllm-serve.modal.run
**Status**: Deployed and responding
**Model**: Qwen3-1.7B with LoRA (v2-4k-pairs checkpoint-700)

#### Test Results ‚úì
```
Input: "papers by kelbert"
Output: author:"kelbert"
Status: ‚úì PASS (no hallucinated initials)

Input: "papers by smith on exoplanets"
Output: author:"smith" abs:"exoplanets"
Status: ‚úì PASS

Input: "trending papers on black holes"
Output: trending(abs:"black hole")
Status: ‚úì PASS

Input: "papers citing gravitational waves"
Output: citations(abs:"gravitational waves")
Status: ‚úì PASS
```

---

## Phase Completion Timeline

### Phase 0: Repository Setup ‚úÖ CLOSED
- Bootstrap nls-finetune-scix repo
- Configure Modal environment
- Set up LoRA training pipeline

### Phase 1: ADS Query Validator ‚úÖ CLOSED
- Created `finetune/domains/scix/fields.py` (40+ ADS fields)
- Implemented offline lint and API validation
- NL validation to detect ADS syntax leakage

### Phase 2: Data Ingestion & Generation ‚úÖ CLOSED
- Gold examples: 267 ‚Üí 4002 regenerated pairs
- Synthetic pairs: 505 examples
- NL generation from query logs: 2000 pairs
- Total: 6507 ‚Üí 3025 after validation/dedup

### Phase 3: Training & Inference ‚úÖ CLOSED
- **Training data**: 2722 train + 303 val examples
- **Categories**: 22 categories (author, first_author, operator, filters, etc.)
- **Key improvement**: 448 author examples (12x from v1)
- **Model checkpoint**: v2-4k-pairs/checkpoint-700
- **Deployment**: Modal vLLM endpoint live
- **Validation**: 4/4 critical tests passing

### Phase 4: Evaluation Harness üîÑ READY
- Depends on Phase 3 ‚úì (now complete)
- Awaiting: Implement result-set overlap metrics
- Task: nls-finetune-scix-ybr

### Phase 5: UI/API Integration üîÑ BLOCKED
- Depends on Phase 4 (evaluation harness)
- Located: ~/ads-dev/nectar branch sj/fine-tune
- Task: nls-finetune-scix-f2w

---

## Key Issues Fixed

### Issue: Author Initial Hallucination ‚úÖ CLOSED
**ID**: nls-finetune-scix-3gw

**Problem**:
- Input: "papers by kelbert"
- v1 Output: author:"kelbert, M" (hallucinated initial "M")
- Root cause: validateAuthors() called ADS autocomplete API

**Solution**:
1. Removed post-processing hacks from API
2. Regenerated training data with 4002 high-quality pairs
3. Model now learns patterns from data, not runtime fixes

**Verification**:
- Test: "papers by kelbert" ‚Üí author:"kelbert" ‚úì
- No hallucinated initials
- Clean JSON output

---

## Architecture Changes

### API Route (`packages/web/src/pages/api/nl-search.ts`)
**Removed** (post-processing hacks):
- ‚ùå validateAuthors() - ADS autocomplete replacement
- ‚ùå resolveObjectNames() - SIMBAD object resolution
- ‚ùå expandSynonyms() - Synonym table expansion

**Kept** (UX features):
- ‚úì generateQueryVariations() - 3-5 alternative queries
- ‚úì applyOperatorPostProcessing() - Fallback for low-coverage operators

**Rationale**: Model should learn correct patterns from training data, not be patched at runtime.

### vLLM Deployment (`serve_vllm.py`)
- Uses mtime-based model selection (loads newest merged)
- Supports instant updates on redeployment
- Single H100 GPU with min_containers=1 for warm starts

---

## Dataset Analysis

### Source
- **File**: ~/Downloads/all_pairs_fixed_regenerated_fielded.json (4002 pairs)
- **Quality**: 99.8% validation pass rate
- **Dedup**: 54% reduction for uniqueness (6507 ‚Üí 3025)

### Category Breakdown (3025 pairs)
| Category | Count | % | Notes |
|----------|-------|---|-------|
| first_author | 853 | 28.2% | ^author: explicit first-author queries |
| unfielded | 557 | 18.4% | Freeform topic searches |
| author | 448 | 14.8% | 12x improvement from v1 |
| content | 286 | 9.5% | Abstract/title topic queries |
| publication | 219 | 7.2% | Journal/date combinations |
| operator | 160 | 5.3% | trending, citations, similar, etc. |
| filters | 153 | 5.1% | pubdate, citation_count ranges |
| compound | 107 | 3.5% | Multi-field combinations |
| Other | 62 | 2.0% | Conversational, metrics, etc. |

### Data Quality Checks
- ‚úì 99.8% valid ADS syntax (6494/6507)
- ‚úì Clear NL-query mapping
- ‚úì Author pattern distinction (first_author vs author)
- ‚úì No duplicate NL or queries (after dedup)
- ‚úì Domain diversity (22 categories)

---

## Training Metrics

- **Dataset**: 2722 training examples
- **Checkpoint**: v2-4k-pairs/checkpoint-700
- **Token accuracy**: ~91% (final epochs)
- **Training time**: ~40 minutes on H100
- **Merge status**: ‚úì Complete
- **Deployment time**: <1 minute

---

## Next Steps

### Immediate (Next Thread)
1. Run Phase 4: Evaluation Harness
   - Compute result-set overlap via ADS API
   - Test 50-100 queries, compare against gold standard
   - Generate evaluation report

2. Integration testing in nectar
   - Test nl-search API endpoint in UI
   - Verify query suggestions work
   - Check result count preview

### Medium Term
1. Phase 5: Full nectar UI integration
2. User acceptance testing
3. Performance optimization if needed
4. Production deployment to SciXplorer

---

## File References

**Model files**:
- `/runs/v2-4k-pairs/merged` (Modal volume)
- Checkpoint: `/runs/v2-4k-pairs/checkpoint-700`

**Training data**:
- Gold: `data/datasets/raw/gold_examples.json` (4002 pairs)
- Training: `data/datasets/processed/train.jsonl` (2722 examples)
- Validation: `data/datasets/processed/val.jsonl` (303 examples)

**Code**:
- API: `packages/web/src/pages/api/nl-search.ts`
- Inference: `packages/finetune/src/finetune/modal/serve_vllm.py`
- Training: `packages/finetune/src/finetune/modal/train.py`
- Merge: `packages/finetune/src/finetune/modal/merge.py`

**Docs**:
- Architecture: `README.md`
- Fine-tuning CLI: `docs/fine-tuning-cli.md`
- Evaluation: (Phase 4 - in progress)

---

## Known Limitations

1. **Operator patterns**: Some operators (topn, similar) may need post-processing fallback for edge cases
2. **Complex queries**: Multi-level nesting not heavily trained
3. **Typos**: Model doesn't handle user typos in names (by design - should validate)
4. **Entity resolution**: No autocomplete integration (removed post-processing hack)

---

## Achievements

‚úÖ Fixed author hallucination regression
‚úÖ Increased author training examples 12x (36 ‚Üí 448)
‚úÖ Deployed clean model without post-processing hacks
‚úÖ All critical tests passing
‚úÖ Ready for evaluation and UI integration
‚úÖ Clear path to production deployment
